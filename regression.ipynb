{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import timeit\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "from numpy import arange\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    # definitions\n",
    "    case_column = \"case concept:name\"\n",
    "    registration_time_column = \"case REG_DATE\"\n",
    "    event_column = \"event concept:name\"\n",
    "    timestamp_column = \"event time:timestamp\"\n",
    "    position_column = \"position\"\n",
    "    baseline_next_event_column = \"Baseline Prediction for Next Activity\"\n",
    "    pos_event_next_event_column = \"Position&Event Prediction for Next Activity\"\n",
    "    baseline_next_timestamp_column = \"Baseline Prediction for Next Timestamp\"\n",
    "    pos_event_next_timestamp_column = \"Position&Event Prediction for Next Timestamp\"\n",
    "    time_since_registration_column = \"Time Since Registration\"\n",
    "    day_of_week_column = \"day_of_week\"\n",
    "    month_of_year_column = \"month_of_year\"\n",
    "    offer_sent = 'offer_sent_already' # the name a of a sent offer state within event_column\n",
    "    timeformat_registration = \"%Y-%m-%dT%H:%M:%S\" # new time format\n",
    "    timeformat_timestamp = \"%d-%m-%Y %H:%M:%S.%f\"\n",
    "    predicted_shift_column = 'Predicted event from baseline'\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    #make timestamps\n",
    "    df[registration_time_column] = [re.sub('\\..*|\\+.*', '', a, flags=re.DOTALL) for a in df[registration_time_column]]\n",
    "    df[registration_time_column] = [datetime.strptime(date, timeformat_registration) for date in df[registration_time_column]]\n",
    "    #df[timestamp_column] = [datetime.strptime(date, timeformat_timestamp) for date in df[timestamp_column]]\n",
    "\n",
    "    #sort and order dataframe\n",
    "    df = df.sort_values(by=[case_column, timestamp_column])\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # add time related columns\n",
    "    df[time_since_registration_column] = df[timestamp_column] - df[registration_time_column] # Adding time since registration\n",
    "    df[day_of_week_column] = df[timestamp_column].dt.dayofweek\n",
    "    df[month_of_year_column] = df[timestamp_column].dt.month\n",
    "    minutes_since_reg= 'minutes_since_reg'\n",
    "    df[minutes_since_reg]=[((i.total_seconds()+0.000001)/60) for i in df[time_since_registration_column]]\n",
    "    hour = 'hour'\n",
    "    df[hour]  = [i.hour for i in df[timestamp_column]]\n",
    "\n",
    "    '''df[offer_sent] = 0\n",
    "    offer_sent_mask = df[event_column] == offer_sent\n",
    "    case_check = df[offer_sent_mask][[case_column,timestamp_column]].copy().reset_index(drop=True)\n",
    "    for i in range(len(case_check)):\n",
    "        case_name = case_check.iloc[i,0]\n",
    "        case_time = case_check.iloc[i,1]\n",
    "        mask = (df[case_column]==case_name)&(df[timestamp_column]>=case_time)\n",
    "        df.loc[mask, offer_sent] = 1'''\n",
    "\n",
    "    # add position column\n",
    "    df[position_column] = df.groupby([case_column]).cumcount()+1\n",
    "\n",
    "    # add time until next event column\n",
    "    shifted_deltatimes_list = df[timestamp_column].diff().shift(periods=-1)\n",
    "    shifted_deltatimes = 'shifted_deltatimes'\n",
    "    df[shifted_deltatimes] = [(i.total_seconds()) for i in shifted_deltatimes_list]\n",
    "    mask1  = (df[shifted_deltatimes]<0.001)\n",
    "    mask2 = (df[shifted_deltatimes]<0)\n",
    "    df.loc[mask1, shifted_deltatimes]=0.001\n",
    "    df.loc[mask2, shifted_deltatimes]=np.nan\n",
    "\n",
    "    # add previous event and previous lifecycle column\n",
    "    df['previous_event']=0\n",
    "    df['previous_lifecycle']=0\n",
    "    all_ids = list(df[case_column].unique())\n",
    "\n",
    "    for ids in all_ids:\n",
    "        df2 = df[df[case_column]==ids].copy()\n",
    "        df.loc[df[case_column]==ids, 'previous_event']= df2[event_column].shift(periods=1)\n",
    "        df.loc[df[case_column]==ids, 'previous_lifecycle']= df2['event lifecycle:transition'].shift(periods=1)\n",
    "    df.loc[df['previous_event'].isnull(), 'previous_event']='START'\n",
    "    df.loc[df['previous_lifecycle'].isnull(), 'previous_lifecycle']='START'\n",
    "\n",
    "    # add binary columns of what events already happened in a case\n",
    "    all_events = list(df['previous_event'].unique())\n",
    "    for event in all_events:\n",
    "        df[event] = 0\n",
    "    df['last_event'] = 0\n",
    "    a=0\n",
    "    for ids in all_ids:\n",
    "        index_case = df[df[case_column]==ids]['index'].max()\n",
    "        df.loc[index_case,'last_event']=1\n",
    "        for i in range(a,index_case+1):\n",
    "            mask = ((df[case_column]==ids)& (df['index']>=i))\n",
    "            prev_event = df.loc[mask,'previous_event'].reset_index(drop=True)[0]\n",
    "            df.loc[mask, prev_event]=1\n",
    "        a = index_case+1\n",
    "\n",
    "    # print time and add log column of time until next event\n",
    "    print((timeit.default_timer() - start_time)/60)\n",
    "    df['log_y'] = np.log(df['shifted_deltatimes'])\n",
    "    return df\n",
    "\n",
    "def prep_data_reg(df):\n",
    "    df_prep = prep_data(df)\n",
    "    mask_nan = df_prep['last_event']==0\n",
    "    df_reg = df_prep[mask_nan].copy()\n",
    "    return df_reg\n",
    "\n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n",
    "\n",
    "def MAE(Y_actual,Y_Predicted):\n",
    "    mae = np.mean(np.abs((Y_actual - Y_Predicted)))\n",
    "    return mae\n",
    "\n",
    "def split_train_data(df_train, df_test):\n",
    "    timeformat_timestamp = \"%d-%m-%Y %H:%M:%S.%f\"\n",
    "    df_train[\"event time:timestamp\"] = [datetime.strptime(date, timeformat_timestamp) for date in df_train[\"event time:timestamp\"]]\n",
    "    df_test[\"event time:timestamp\"] = [datetime.strptime(date, timeformat_timestamp) for date in df_test[\"event time:timestamp\"]]\n",
    "    max_time_train = min(df_test['event time:timestamp'])\n",
    "    for i in range((round(len(df_train)/2)), len(df_train)):\n",
    "        if df_train['event time:timestamp'][i] > max_time_train:\n",
    "            print(df_train['event time:timestamp'][i])\n",
    "            df_train2 = df_train[:i].copy()\n",
    "            break\n",
    "    return df_train2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/BPI_Challenge_2012-training.csv')\n",
    "df_t = pd.read_csv('data/BPI_Challenge_2012-test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-02-03 17:18:54.290000\n",
      "9.047306868333331\n",
      "0.7931459483333356\n"
     ]
    }
   ],
   "source": [
    "df_split = split_train_data(df,df_t)\n",
    "df_train = prep_data_reg(df_split)\n",
    "df_test = prep_data_reg(df_t)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0\n",
      "MAPE: 456927.6896794171\n",
      "MAE: 9.531040677931124 hours\n",
      "R2: 0.34004697565053843\n"
     ]
    }
   ],
   "source": [
    "X = df_train[['day_of_week', 'hour', 'month_of_year','position','minutes_since_reg', 'case AMOUNT_REQ', 'START', 'A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_PREACCEPTED', 'W_Completeren aanvraag', 'A_DECLINED', 'A_ACCEPTED', 'A_FINALIZED', 'O_SELECTED', 'O_CREATED', 'O_SENT', 'W_Nabellen offertes', 'O_CANCELLED', 'W_Afhandelen leads', 'A_CANCELLED', 'O_SENT_BACK', 'W_Valideren aanvraag', 'O_ACCEPTED', 'A_APPROVED', 'A_REGISTERED', 'A_ACTIVATED', 'O_DECLINED', 'W_Nabellen incomplete dossiers', 'W_Beoordelen fraude']]\n",
    "y = df_train['log_y']\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "model = RidgeCV(alphas=arange(0, 1, 0.01), cv=cv, scoring='neg_mean_absolute_error')\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "print(f'Alpha: {model.alpha_}')\n",
    "\n",
    "X_test = df_test[['day_of_week', 'hour', 'month_of_year','position','minutes_since_reg', 'case AMOUNT_REQ', 'START', 'A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_PREACCEPTED', 'W_Completeren aanvraag', 'A_DECLINED', 'A_ACCEPTED', 'A_FINALIZED', 'O_SELECTED', 'O_CREATED', 'O_SENT', 'W_Nabellen offertes', 'O_CANCELLED', 'W_Afhandelen leads', 'A_CANCELLED', 'O_SENT_BACK', 'W_Valideren aanvraag', 'O_ACCEPTED', 'A_APPROVED', 'A_REGISTERED', 'A_ACTIVATED', 'O_DECLINED', 'W_Nabellen incomplete dossiers', 'W_Beoordelen fraude']]\n",
    "Y_test = df_test['shifted_deltatimes']\n",
    "ridge_predict = np.exp(model.predict(X_test))\n",
    "ridge_MAPE = MAPE(Y_test,ridge_predict)\n",
    "ridge_MAE = MAE(Y_test,ridge_predict)\n",
    "r2 = model.score(X_test,df_test['log_y'])\n",
    "print(f'MAPE: {ridge_MAPE}')\n",
    "print(f'MAE: {ridge_MAE/3600} hours')\n",
    "print(f'R2: {r2}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 5.05698284e-02,  7.90357299e-02,  8.45807231e-03,  1.91786689e-02,\n       -9.00419107e-06, -2.63848332e-06, -3.69433512e+09,  4.50964467e+00,\n        4.97113333e-03,  2.04004906e+00,  7.95090073e-01, -3.51447311e+00,\n       -1.07878945e+01,  9.67749572e-01,  2.05893261e+00, -4.18521413e-01,\n        2.28285058e+00,  5.02739317e+00, -1.57739590e+00, -4.12299957e-01,\n       -4.40605035e+00, -4.40678094e+00,  4.10610140e+00, -6.36926289e+00,\n       -2.63261834e+00, -2.63974782e-01, -4.17866519e-01, -3.42910073e+00,\n        1.23151406e-01, -8.41922452e-02])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}