{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### IMPORT PACKAGES ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to make pretty plots\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# to play with time :-)\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook can be run separately from the deliverable tool.\n",
    "if (('df' not in globals()) or ('df_test' not in globals())):\n",
    "    ### IMPORT THE DATA ###\n",
    "    df = pd.read_csv('data/BPI_Challenge_2012-training.csv')\n",
    "    df_test = pd.read_csv('data/BPI_Challenge_2012-test.csv')\n",
    "\n",
    "    # Defining database-specific variables\n",
    "    case_column = \"case concept:name\"\n",
    "    event_column = \"event concept:name\"\n",
    "    timestamp_column = \"event time:timestamp\"\n",
    "    timeformat_timestamp = \"%d-%m-%Y %H:%M:%S.%f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case concept:name      event concept:name     event time:timestamp  \\\n",
      "0             173688             A_SUBMITTED  01-10-2011 00:38:44.546   \n",
      "1             173688       A_PARTLYSUBMITTED  01-10-2011 00:38:44.880   \n",
      "2             173688           A_PREACCEPTED  01-10-2011 00:39:37.906   \n",
      "3             173688  W_Completeren aanvraag  01-10-2011 00:39:38.875   \n",
      "4             173691             A_SUBMITTED  01-10-2011 08:08:58.256   \n",
      "\n",
      "  event lifecycle:transition  row_nr  \n",
      "0                   COMPLETE       0  \n",
      "1                   COMPLETE       1  \n",
      "2                   COMPLETE       2  \n",
      "3                   SCHEDULE       3  \n",
      "4                   COMPLETE       4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20182960\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\20182960\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "row_nr_column = 'row_nr'\n",
    "additionalInfo = ['event lifecycle:transition']\n",
    "\n",
    "# do you want any error plots?\n",
    "printPlots = False\n",
    "# do you want to write the plots to html?\n",
    "writePlots = False\n",
    "\n",
    "\n",
    "# events that are influenced by concurency\n",
    "eventList = ['A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_PREACCEPTED', 'O_SELECTED', 'A_FINALIZED', 'O_ACCEPTED']\n",
    "\n",
    "# variables\n",
    "weight_newtimePassed = 0.1\n",
    "\n",
    "# make a list of the columns you need\n",
    "columns = [case_column, event_column, timestamp_column]\n",
    "columns.extend(additionalInfo)\n",
    "\n",
    "# you can get rid of all the other columns, to make things faster\n",
    "dataset = df[columns]\n",
    "dataset_test = df_test[columns]\n",
    "dataset[row_nr_column] = dataset.index\n",
    "dataset_test[row_nr_column] = dataset_test.index\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20182960\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "### ON THE FLY ###\n",
    "# This has two practical implications that we should be aware of\n",
    "# 1) You can't preprocess the data, when a new event comes in, you have to be able to process it on the spot\n",
    "# 2) You don't have any historical data, so your predictions can only rely on the things you have seen before\n",
    "\n",
    "# This means that the data needs to be sorted on timestamp_column\n",
    "# you need to first convert to a datetime, because otherwise you'll sort the strings\n",
    "# and since the day of the month is the first part of the string, you will first get all firsts of all months, etc.\n",
    "dataset.loc[:,timestamp_column] = pd.to_datetime(dataset.loc[:,timestamp_column], format=timeformat_timestamp)\n",
    "dataset = dataset.sort_values(by=timestamp_column)\n",
    "\n",
    "dataset_test.loc[:,timestamp_column] = pd.to_datetime(dataset_test.loc[:,timestamp_column], format=timeformat_timestamp)\n",
    "dataset_test = dataset_test.sort_values(by=timestamp_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### STORAGE ###\n",
    "# we want to keep track of things that happen within one instance (also called trace or case)\n",
    "\n",
    "# instanceStorage stores: key=instance, values= [event_column, timestamp_column, predictedDuration],\n",
    "# to look up the previous event in this instance, and it's predicted TimePassed\n",
    "instanceStorage = {}\n",
    "\n",
    "# we also want to keep track of the predictionError\n",
    "# errorStorage stores: key=unique integer, values= [previousEvent, previousTimestamp, predictionError, predictionErrorRatio, predictedTimePassed, timePassed]\n",
    "errorStorage = {}\n",
    "\n",
    "\n",
    "# we also want to add a log feature => we don't have to save this seperatly, just needed to check if having it makes sense.\n",
    "# how many events of the same activty are running at the same time might be interesting\n",
    "# concurentEvents = {}\n",
    "\n",
    "def updateStorage(case, event, timestamp, row_nr, predictedDuration):\n",
    "    \"\"\"\n",
    "    :param case: string; the case_id, so which instance this event belongs to\n",
    "    :param event: string; the id of the event we're evaluating\n",
    "    :param timestamp: pandas datetime; the time of the event that we're evaluating\n",
    "    :param row_nr: int; unique id in the dataset\n",
    "    :param predictedDuration: float; the predicted time for this event\n",
    "    (which you need to store to calculate the error when you know the real time passed when the next event comes in)\n",
    "    :return: previousEvent, timePassed; string, pandas datetime delta;\n",
    "    the id of the previous event and the time that passed since that event, you need this information to update the model\n",
    "    \"\"\"\n",
    "\n",
    "    # if this instance is already in the instanceStorage, we have a previous event\n",
    "    if case in instanceStorage:\n",
    "\n",
    "        # find the previous event\n",
    "        previousEvent = instanceStorage[case][0]\n",
    "        previousRow_nr = instanceStorage[case][3]\n",
    "\n",
    "        # calculate the time passed between the previous event and this event\n",
    "        thisTimestamp = pd.to_datetime(timestamp, format=timeformat_timestamp)\n",
    "        previousTimestamp = pd.to_datetime(instanceStorage[case][1], format=timeformat_timestamp)\n",
    "        timePassed = (thisTimestamp - previousTimestamp)/ datetime.timedelta(minutes=1)\n",
    "\n",
    "        # since we have also saved the predicted time between the previous event and this event,\n",
    "        # we can now also compute the difference\n",
    "\n",
    "        predictedTimePassed = instanceStorage[case][2]\n",
    "        if predictedTimePassed != None:\n",
    "            predictionError = abs(predictedTimePassed - timePassed)\n",
    "            if timePassed > 0:\n",
    "                predictionErrorRatio = predictionError/timePassed\n",
    "            else:\n",
    "                predictionErrorRatio = None\n",
    "        else:\n",
    "            predictionError = None\n",
    "            predictionErrorRatio = None\n",
    "            predictedTimePassed = None\n",
    "\n",
    "\n",
    "        # the key is now the row number of the event that is in the values\n",
    "        errorStorage[previousRow_nr] = [previousEvent, previousTimestamp, predictionError, predictionErrorRatio, predictedTimePassed, timePassed]\n",
    "\n",
    "    # otherwise we don't have a previous event\n",
    "    else:\n",
    "        previousEvent = None\n",
    "        timePassed = None\n",
    "\n",
    "    # key = case_column (so which case we're looking at), and the values are the activity and the timestamp\n",
    "    instanceStorage[case] = [event, timestamp, predictedDuration, row_nr]\n",
    "\n",
    "\n",
    "    # update concurentEvents -> I only used this once to be able to make pretty plots showing if it would have effect or not\n",
    "    # howManyConcurentEvents = [x[0] for x in instanceStorage.values()].count(previousEvent)\n",
    "    # concurentEvents[row_nr] = [previousEvent, howManyConcurentEvents, timePassed, row_nr]\n",
    "\n",
    "    return previousEvent, timePassed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### THE MODEL ###\n",
    "# We start with only one feature: the historical average time between two events based on the previous event\n",
    "# You don't need a second model for the test set, since you train your model on the training-set and then use it on the test-set\n",
    "\n",
    "predictionModel = {}\n",
    "\n",
    "def getPrediction(event):\n",
    "    \"\"\"\n",
    "    :param event: string; the name of the activity for which you want a prediction of time until the next event\n",
    "    :return: float (or None); predicted time until the next event in this instance, if there is already data on this activity,\n",
    "    otherwise None\n",
    "    \"\"\"\n",
    "\n",
    "    # if this activity is already in the predictionModel, then return the predicted duration\n",
    "    # try & except works slightly faster then if key in dict\n",
    "    # but only for valid keys, since you skip the if statement\n",
    "    try:\n",
    "        return predictionModel[event]\n",
    "\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "def updatePredictionModel(this_event_id, timePassed, weight_newtimePassed):\n",
    "    \"\"\"\n",
    "    :param this_event_id: string; the slicing-id of the current event\n",
    "    :param timePassed: datatime delta; the time between the previous event in this instance and the current event\n",
    "    :param weight_newtimePassed: float; how much weight should the new timePassed have in the update\n",
    "    :return: None\n",
    "    It will update the global variable predictionModel\n",
    "    \"\"\"\n",
    "\n",
    "    if timePassed != None:\n",
    "\n",
    "        # if this activity is already in the predictionModel, update the model\n",
    "        # try & except works slightly faster then if key in dict\n",
    "        # but only for valid keys, since you skip the if statement\n",
    "        try:\n",
    "            predictionModel[this_event_id] = timePassed*weight_newtimePassed + predictionModel[this_event_id]*(1-weight_newtimePassed)\n",
    "\n",
    "        except:\n",
    "            predictionModel[this_event_id] = timePassed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict: Elapsed time during the whole program in seconds: 116.8125\n"
     ]
    }
   ],
   "source": [
    "### RUNNING THE MODEL ###\n",
    "# We have to run the model line by line, we can't do things in parallel, otherwise it's not on the fly\n",
    "\n",
    "def processEvent(case, event, additional, timestamp, row_nr, includeAdditional=True):\n",
    "    \"\"\"\n",
    "    :param case: string; the case_id, so which instance this event belongs to\n",
    "    :param event: string; the id of the event we're evaluating\n",
    "    :param additional: string or number; something additional that you want to slice on\n",
    "    :param timestamp: pandas datetime; the time of the event that we're evaluating\n",
    "    :param row_nr: int; unique id in the dataset\n",
    "    :param includeAdditional: bool, if you want to include additional information to slice on or you want the baseline model\n",
    "    :return: None\n",
    "    It updates the global variables predictionModel, instanceStorage and errorStorage\n",
    "    \"\"\"\n",
    "\n",
    "    # step 1: preProcess the incoming event -> create an event_id that indicates the dataSlice that you want to use\n",
    "    # The event-id is where you want to slice the data on before you take the average timePassed\n",
    "    # If you don't want to include any additional information, this is just the event itself\n",
    "    # otherwise include it in the event_id to make sure that you slice on everything you want to slice on\n",
    "    if includeAdditional == True:\n",
    "\n",
    "        if event in eventList:\n",
    "            # you want to find how many times this activity occurs without any additional information\n",
    "            howManyConcurentEvents = [x[0].split('_XX_')[0] for x in instanceStorage.values()].count(event)\n",
    "            event_id = event+'_XX_'+additional+'_XX_'+str(howManyConcurentEvents)\n",
    "        else:\n",
    "            event_id = event+'_XX_'+additional\n",
    "    else:\n",
    "        event_id = event\n",
    "\n",
    "\n",
    "    # step 2: predict\n",
    "    # look up if this event is already in predictionModel\n",
    "    # if it is, use the predictedDuration as current prediction\n",
    "    # otherwise predict: unknown\n",
    "    predictedDuration = getPrediction(event_id)\n",
    "\n",
    "    # step 3: loop up historical data\n",
    "    # you only know things of the past, so you want to check if there is a previous event in the instanceStorage\n",
    "    # if there is, you can calculate the duration between that event and this one\n",
    "    previousEvent, timePassed = updateStorage(case, event_id , timestamp, row_nr, predictedDuration)\n",
    "\n",
    "    # step 4: update predictionModel\n",
    "    updatePredictionModel(previousEvent, timePassed, weight_newtimePassed)\n",
    "\n",
    "\n",
    "\n",
    "### Run over all lines =>\n",
    "# let's first do a simple for-loop, maybe I can improve the running time by using .apply later on\n",
    "#mini_dataset = dataset.loc[0:1000, :]\n",
    "#print(mini_dataset)\n",
    "# Start the stopwatch / counter\n",
    "\n",
    "# Start the stopwatch / counter\n",
    "start_time = time.process_time()\n",
    "\n",
    "# running the on-the-fly model for each row\n",
    "# I have tested it, ... for ... in ... does iterate over all events in order\n",
    "# so we're not using information from the future.\n",
    "[processEvent(case, event, additional, timestamp, row_nr, includeAdditional=True) for case,event,additional,timestamp,row_nr in zip(dataset[case_column],dataset[event_column], dataset[additionalInfo].iloc[:,0], dataset[timestamp_column], dataset[row_nr_column])]\n",
    "\n",
    "# Stop the stopwatch / counter\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(\"dict: Elapsed time during the whole program in seconds:\", end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "concurent_df = pd.DataFrame.from_dict(concurentEvents, orient='index', columns=['event_id', 'concurent_events', 'timePassed','row_nr'])\n",
    "print(concurent_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20182960\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: divide by zero encountered in log2\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the training-set is: 725.8 minutes.\n"
     ]
    }
   ],
   "source": [
    "### THE PREDICTION ERROR ###\n",
    "# plot different things to get more insight\n",
    "# first the difference in time passed\n",
    "# then the log of the difference in time passed\n",
    "# then the ratio between the difference in time passed and the real time passed\n",
    "\n",
    "# flatten the error dictionary to a dataframe\n",
    "error_df = pd.DataFrame.from_dict(errorStorage, orient='index', columns=['event_column', 'timestamp', 'predictionError', 'predictionErrorRatio', 'predictedTimePassed', 'timePassed'])\n",
    "error_df.loc[:,'timestamp'] = pd.to_datetime(error_df.loc[:,'timestamp'])\n",
    "error_df = error_df.sort_values(by='timestamp')\n",
    "error_df['event_column_basic'] = error_df.event_column.str.split('_XX_').str.get(0)\n",
    "\n",
    "# calculate the log of the prediction error\n",
    "error_df['log_predictionError'] = [np.log2(x) for x in error_df['predictionError']]\n",
    "\n",
    "# calculate statistics\n",
    "mae = np.mean(error_df['predictionError'])\n",
    "print('The mean absolute error on the training-set is: ' + str(round(mae, 2)) + ' minutes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### HISTOGRAMS ###\n",
    "\n",
    "if printPlots == True:\n",
    "    # make the prediction error plot\n",
    "    fig= px.line(error_df, x='timestamp', y='predictionError', color='event_column')\n",
    "    fig.update_layout(title='Prediction error (difference in timePassed between real timePassed an predicted timePassed) per activity')\n",
    "    fig.show()\n",
    "    if writePlots == True:\n",
    "        fig.write_html(\"images/predictionError_withboth.html\")\n",
    "\n",
    "    # make the log prediction error plot\n",
    "    fig= px.line(error_df, x='timestamp', y='log_predictionError', color='event_column')\n",
    "    fig.update_layout(title='Prediction error ratio (log of the difference in timePassed) per activity')\n",
    "    fig.show()\n",
    "    if writePlots == True:\n",
    "        fig.write_html(\"images/log_predictionError_withboth.html\")\n",
    "\n",
    "    # make the ratio prediction error plot\n",
    "    fig= px.line(error_df, x='timestamp', y='predictionErrorRatio', color='event_column')\n",
    "    fig.update_layout(title='Prediction error ratio (difference in timePassed divided by real timePassed) per activity')\n",
    "    fig.show()\n",
    "    if writePlots==True:\n",
    "        fig.write_html(\"images/predictionErrorRatio_withboth.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### BOXPLOTS ###\n",
    "\n",
    "if printPlots == True:\n",
    "    fig = px.box(error_df, y='predictionError', color='event_column_basic')\n",
    "    fig.show()\n",
    "    if writePlots == True:\n",
    "        fig.write_html('images/box_predictionError_withboth.html')\n",
    "\n",
    "\n",
    "    fig = px.box(error_df, y='predictionErrorRatio', color='event_column_basic')\n",
    "    fig.show()\n",
    "    if writePlots == True:\n",
    "        fig.write_html('images/box_predictionErrorRatio_withboth.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if printPlots == True:\n",
    "    for activity in eventList:\n",
    "        fig=px.box(error_df[error_df['event_column_basic'] == activity], y='predictionError', color='event_column')\n",
    "        fig.show()\n",
    "        if writePlots == True:\n",
    "            fig.write_html('images/box_predictionError_splitForConcurentEvents.html')\n",
    "\n",
    "# there is a difference in error distribution, so it looks like it does have an effect.\n",
    "# I don't save the timePassed anywhere, so I can't check on that. But in the InfluenceOnTime file I have tested that there is indeed a\n",
    "# different distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict: Elapsed time during the whole program on the testset in seconds: 6.84375\n"
     ]
    }
   ],
   "source": [
    "### RUN ON THE TEST SET ###\n",
    "# You can use the model that you have created during the train, so you don't have to start with empty model\n",
    "# but you do have to start with an empty storage\n",
    "\n",
    "instanceStorage = {}\n",
    "errorStorage = {}\n",
    "\n",
    "# Start the stopwatch / counter\n",
    "start_time = time.process_time()\n",
    "\n",
    "# running the on-the-fly model for each row\n",
    "# I have tested it, ... for ... in ... does iterate over all events in order\n",
    "# so we're not using information from the future.\n",
    "[processEvent(case, event, additional, timestamp, row_nr, includeAdditional=True) for case,event,additional,timestamp,row_nr in zip(dataset_test[case_column],dataset_test[event_column], dataset_test[additionalInfo].iloc[:,0], dataset_test[timestamp_column], dataset_test[row_nr_column])]\n",
    "\n",
    "# Stop the stopwatch / counter\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(\"dict: Elapsed time during the whole program on the testset in seconds:\", end_time-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error on the test-set is: 619.86 minutes.\n"
     ]
    }
   ],
   "source": [
    "### THE PREDICTION ERROR ###\n",
    "# plot different things to get more insight\n",
    "# first the difference in time passed\n",
    "# then the log of the difference in time passed\n",
    "# then the ratio between the difference in time passed and the real time passed\n",
    "\n",
    "# flatten the error dictionary to a dataframe\n",
    "error_df_test = pd.DataFrame.from_dict(errorStorage, orient='index', columns=['event_column', 'timestamp', 'predictionError', 'predictionErrorRatio', 'predictedTimePassed', 'timePassed'])\n",
    "error_df_test.loc[:,'timestamp'] = pd.to_datetime(error_df_test.loc[:,'timestamp'])\n",
    "error_df_test = error_df_test.sort_values(by='timestamp')\n",
    "error_df_test['event_column_basic'] = error_df_test.event_column.str.split('_XX_').str.get(0)\n",
    "\n",
    "# calculate the log of the prediction error\n",
    "error_df_test['log_predictionError'] = [np.log2(x) for x in error_df_test['predictionError']]\n",
    "\n",
    "# calculate statistics\n",
    "mae = np.mean(error_df_test['predictionError'])\n",
    "print('The mean absolute error on the test-set is: ' + str(round(mae, 2)) + ' minutes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              eventID   case concept:name                  case REG_DATE  \\\n",
      "214375  35858681954366             199678  2012-01-10T19:16:52.800+01:00   \n",
      "214376  35858681954367             199678  2012-01-10T19:16:52.800+01:00   \n",
      "\n",
      "        case AMOUNT_REQ   event concept:name event lifecycle:transition  \\\n",
      "214375            30000  W_Nabellen offertes                      START   \n",
      "214376            30000  W_Nabellen offertes                   COMPLETE   \n",
      "\n",
      "           event time:timestamp  \n",
      "214375  14-03-2012 15:36:15.299  \n",
      "214376  14-03-2012 15:40:34.231  \n",
      "                        event_column               timestamp  predictionError  \\\n",
      "214375  W_Nabellen offertes_XX_START 2012-03-14 15:36:15.299         1.428251   \n",
      "\n",
      "        predictionErrorRatio  predictedTimePassed  timePassed  \\\n",
      "214375              0.330956             2.887283    4.315533   \n",
      "\n",
      "         event_column_basic  log_predictionError  \n",
      "214375  W_Nabellen offertes             0.514249  \n"
     ]
    }
   ],
   "source": [
    "### MERGE ORIGINAL DATAFRAME WITH THE ERROR DF ###\n",
    "\n",
    "total_df = df.join(error_df)\n",
    "\n",
    "# check if this works properly\n",
    "# but this should be a left join on the dataframe, and the index should match"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### BOXPLOTS ###\n",
    "\n",
    "if printPlots == True:\n",
    "    fig = px.box(error_df_test, y='predictionError', color='event_column_basic', title='PredictionError on the test-dataset')\n",
    "    fig.show()\n",
    "    if writePlots == True:\n",
    "        fig.write_html('images/TEST_box_predictionError_withboth.html')\n",
    "\n",
    "\n",
    "    fig = px.box(error_df_test, y='predictionErrorRatio', color='event_column_basic', title='PredictionErrorRatio on the test-dataset')\n",
    "    fig.show()\n",
    "    if writePlots == True:\n",
    "        fig.write_html('images/TEST_box_predictionErrorRatio_withboth.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         event_column               timestamp  \\\n",
      "0        A_SUBMITTED_XX_COMPLETE_XX_0 2012-02-03 17:17:11.047   \n",
      "1  A_PARTLYSUBMITTED_XX_COMPLETE_XX_0 2012-02-03 17:17:11.323   \n",
      "3        A_SUBMITTED_XX_COMPLETE_XX_0 2012-02-03 17:23:41.949   \n",
      "4  A_PARTLYSUBMITTED_XX_COMPLETE_XX_0 2012-02-03 17:23:42.504   \n",
      "5      A_PREACCEPTED_XX_COMPLETE_XX_0 2012-02-03 17:24:23.379   \n",
      "\n",
      "   predictionError  predictionErrorRatio  predictedTimePassed  timePassed  \\\n",
      "0         0.004439              0.964925             0.009039    0.004600   \n",
      "1         0.008243              0.015630             0.535593    0.527350   \n",
      "3         0.000655              0.070834             0.008595    0.009250   \n",
      "4         0.146482              0.215019             0.534768    0.681250   \n",
      "5         0.002926              0.260872             0.008291    0.011217   \n",
      "\n",
      "  event_column_basic  log_predictionError  \n",
      "0        A_SUBMITTED            -7.815662  \n",
      "1  A_PARTLYSUBMITTED            -6.922686  \n",
      "3        A_SUBMITTED           -10.575755  \n",
      "4  A_PARTLYSUBMITTED            -2.771208  \n",
      "5      A_PREACCEPTED            -8.416799  \n"
     ]
    }
   ],
   "source": [
    "print(error_df_test.head(5))\n",
    "\n",
    "### MERGE ORIGINAL DATAFRAME WITH THE ERROR DF ###\n",
    "\n",
    "total_df_test = df_test.join(error_df_test)\n",
    "\n",
    "# check if this works properly\n",
    "# but this should be a left join on the dataframe, and the index should match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# to make an accurate prediction, it is important to know how much variance there is when you only take the previous event into account.\n",
    "# because if there is still a lot of variance, you can never make an accurate prediction.\n",
    "\n",
    "activities = pd.unique(error_df['event_column_basic'])\n",
    "\n",
    "\n",
    "for activity in activities:\n",
    "\n",
    "    print(activity)\n",
    "    subset = error_df[error_df['event_column_basic'] == activity]['predictionError']\n",
    "    print(np.mean(subset))\n",
    "    print(np.std(subset))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "concurent_df[event_column] = concurent_df.event_id.str.split('_XX_').str.get(0)\n",
    "concurent_df2 = concurent_df.dropna()\n",
    "\n",
    "for activity in pd.unique(concurent_df2[event_column]):\n",
    "\n",
    "    print(activity)\n",
    "    fig= px.box(concurent_df2[concurent_df2[event_column] == activity], y='timePassed', color='concurent_events')\n",
    "    fig.show()\n",
    "    fig.write_html(activity+'_concurentEvents.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "concurent_df2.to_csv('data/concurent_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}