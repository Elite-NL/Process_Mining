{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### IMPORT PACKAGES ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to make pretty plots\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# to play with time :-)\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', '_i', '_ii', '_iii', '_i1', 'pd', 'np', 'plotly', 'px', 'go', 'datetime', 'time', '_i2'])\n"
     ]
    }
   ],
   "source": [
    "print(globals().keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT THE DATA ###\n",
    "\n",
    "if (('df' not in globals()) or ('df_test' not in globals() or ('df_validation' not in globals()))):\n",
    "    ### IMPORT THE DATA ###\n",
    "    df = pd.read_csv('data/BPI_Challenge_2012-training.csv')\n",
    "    df_test = pd.read_csv('data/BPI_Challenge_2012-test.csv')\n",
    "    df_validation = pd.read_csv('final data/BPI_Challenge_2012-validation.csv')\n",
    "    case_column = \"case concept:name\"\n",
    "    event_column = \"event concept:name\"\n",
    "    timestamp_column = \"event time:timestamp\"\n",
    "    timeformat_timestamp = \"%Y-%m-%d %H:%M:%S.%f\"\n",
    "    lifecycle_column = 'event lifecycle:transition'\n",
    "    amount_column = 'case AMOUNT_REQ'\n",
    "    row_nr_column = 'row_nr'\n",
    "    pred_event_otf = \"OTF Prediction for Next Activity\"\n",
    "    df.loc[:,timestamp_column] = pd.to_datetime(df.loc[:,timestamp_column])#, format=timeformat_timestamp)\n",
    "    df_validation.loc[:,timestamp_column] = pd.to_datetime(df_validation.loc[:,timestamp_column])#, format=timeformat_timestamp)\n",
    "    df_test.loc[:,timestamp_column] = pd.to_datetime(df_test.loc[:,timestamp_column])#, format=timeformat_timestamp)\n",
    "\n",
    "\n",
    "if ('amount_column_in_data' not in globals()):\n",
    "    amount_column_in_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#make a list with all possible events\n",
    "all_events=list(df[event_column].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# get most common event\n",
    "df_most_common_event =pd.DataFrame(df[event_column].value_counts())\n",
    "df_most_common_event.reset_index(inplace=True)\n",
    "most_common_event = df_most_common_event.iloc[0,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df = df.sort_values(by=timestamp_column).reset_index(drop=True)\n",
    "df_validation = df_validation.sort_values(by=timestamp_column).reset_index(drop=True)\n",
    "df_test = df_test.sort_values(by=timestamp_column).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_4820/1261009798.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[row_nr_column] = dataset.index\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_4820/1261009798.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_val[row_nr_column] = dataset_val.index\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_4820/1261009798.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_test[row_nr_column] = dataset_test.index\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_4820/1261009798.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[amount_column] = [round(int(x),-4) for x in dataset[amount_column]]\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_4820/1261009798.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_val[amount_column] = [round(int(x),-4) for x in dataset_val[amount_column]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case concept:name      event concept:name event lifecycle:transition  \\\n",
      "0             173688             A_SUBMITTED                   COMPLETE   \n",
      "1             173688       A_PARTLYSUBMITTED                   COMPLETE   \n",
      "2             173688           A_PREACCEPTED                   COMPLETE   \n",
      "3             173688  W_Completeren aanvraag                   SCHEDULE   \n",
      "4             173691             A_SUBMITTED                   COMPLETE   \n",
      "\n",
      "     event time:timestamp  case AMOUNT_REQ  row_nr  \n",
      "0 2011-01-10 00:38:44.546            20000       0  \n",
      "1 2011-01-10 00:38:44.880            20000       1  \n",
      "2 2011-01-10 00:39:37.906            20000       2  \n",
      "3 2011-01-10 00:39:38.875            20000       3  \n",
      "4 2011-01-10 08:08:58.256                0       4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_4820/1261009798.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_test[amount_column] = [round(int(x),-4) for x in dataset_test[amount_column]]\n"
     ]
    }
   ],
   "source": [
    "# additional columns that you want to include\n",
    "additionalInfo = []\n",
    "\n",
    "if amount_column_in_data == True:\n",
    "    if amount_column not in list(df):\n",
    "        amount_column = 'case RequestedAmount'\n",
    "    additionalInfo.append(amount_column)\n",
    "\n",
    "\n",
    "# make a list of the columns you need\n",
    "columns = [case_column, event_column, lifecycle_column, timestamp_column]\n",
    "columns.extend(additionalInfo)\n",
    "\n",
    "\n",
    "# you can get rid of all the other columns, to make things faster\n",
    "\n",
    "place =1\n",
    "dataset = df[columns]\n",
    "dataset_val = df_validation[columns]\n",
    "dataset_test = df_test[columns]\n",
    "dataset[row_nr_column] = dataset.index\n",
    "dataset_val[row_nr_column] = dataset_val.index\n",
    "dataset_test[row_nr_column] = dataset_test.index\n",
    "\n",
    "if amount_column_in_data!=True:\n",
    "    dataset[amount_column] = [0 for i in range(len(dataset))]\n",
    "    dataset_val[amount_column] = [0 for i in range(len(dataset_val))]\n",
    "    dataset_test[amount_column] = [0 for i in range(len(dataset_test))]\n",
    "\n",
    "\n",
    "# round the amount column on 10000\n",
    "if amount_column in list(dataset):\n",
    "    dataset[amount_column] = [round(int(x),-4) for x in dataset[amount_column]]\n",
    "    dataset_val[amount_column] = [round(int(x),-4) for x in dataset_val[amount_column]]\n",
    "    dataset_test[amount_column] = [round(int(x),-4) for x in dataset_test[amount_column]]\n",
    "\n",
    "\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### STORAGE ###\n",
    "# we want to keep track of things that happen within one case\n",
    "\n",
    "# caseStorage stores: key=instance, values= [event, previousEvent, event_id, previousEvent_id, lifecycle, previousLifecycle, amount, predictedEvent]\n",
    "# to look up the previous event in this instance, and it's predicted TimePassed\n",
    "caseStorage = {}\n",
    "\n",
    "# we also want to keep track of the predictionError\n",
    "# errorStorage stores: key=unique integer, values= [previousEvent, previousLifecycle, predictionError,predictedEvent, event]\n",
    "errorStorage = {}\n",
    "\n",
    "# we also want to add a log feature => we don't have to save this seperatly, just needed to check if having it makes sense.\n",
    "# how many events of the same activty are running at the same time might be interesting\n",
    "# concurentEvents = {}\n",
    "\n",
    "def getFeatures(case, event):\n",
    "    \"\"\"\n",
    "    This function extracts extra info of incomming event from the caseStorage\n",
    "    \"\"\"\n",
    "\n",
    "    # if the case is already in storage, info of previous event is extracted from caseStorage\n",
    "    if case in caseStorage:\n",
    "\n",
    "        previousEvent = caseStorage[case][0]\n",
    "        previousLifecycle = caseStorage[case][4]\n",
    "        predictedEvent = caseStorage[case][7]\n",
    "        previousEvent_id = caseStorage[case][2]\n",
    "        previousRow_nr = caseStorage[case][8]\n",
    "\n",
    "        # if prediction of previous event is correct, change predictionError to 1 and add the event to errorstorage\n",
    "        if predictedEvent == event:\n",
    "            predictionError = 1\n",
    "        else:\n",
    "            predictionError = 0\n",
    "        errorStorage[previousRow_nr] = [previousEvent, previousLifecycle, predictionError,predictedEvent, event]\n",
    "\n",
    "    # if it is a new case set info of previous event to None\n",
    "    else:\n",
    "        previousEvent = None\n",
    "        previousEvent_id = None\n",
    "        previousLifecycle = None\n",
    "\n",
    "    #if event in eventList:\n",
    "        # you want to find how many times this activity occurs without any additional information\n",
    "        #howManyConcurentEvents = [x[0] for x in caseStorage.values()].count(event)\n",
    "    #else:\n",
    "        #howManyConcurentEvents = ''\n",
    "\n",
    "    howManyConcurentEvents = [x[0] for x in caseStorage.values()].count(event)\n",
    "    #howManyConcurentEvents = [x[0].split('_XX_')[0] for x in instanceStorage.values()].count(event)\n",
    "    if howManyConcurentEvents > 3:\n",
    "        # when an event is the last event in an instance, it won't get out of the instance storage\n",
    "        # so this number can get really high for events that are common to be the last one\n",
    "        # even though they are not actually running at the same time. Therefore I will top it off at 3.\n",
    "        howManyConcurentEvents = 3\n",
    "    #howManyConcurentEvents= ''\n",
    "\n",
    "    return previousEvent, previousEvent_id, previousLifecycle, howManyConcurentEvents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### THE MODEL ###\n",
    "# We start with only one feature: the historical average time between two events based on the previous event\n",
    "# You don't need a second model for the test set, since you train your model on the training-set and then use it on the test-set\n",
    "\n",
    "predictionModel = {}\n",
    "\n",
    "def getPrediction(event_id):\n",
    "    \"\"\"\n",
    "    gets the prediction of a certain event_id\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # get the event of an event_id with the highest occurrence\n",
    "        return sorted(predictionModel[event_id],key=predictionModel[event_id].get)[-place]\n",
    "\n",
    "    except:\n",
    "        # if event_id not in predictionModel return the most frequent event in train data as prediction\n",
    "        return most_common_event\n",
    "\n",
    "\n",
    "\n",
    "def updatePredictionModel(this_event_id, event):\n",
    "    \"\"\"\n",
    "    updates PredictionModel with the true event of a event_id\n",
    "    \"\"\"\n",
    "    # makes dict with all events as key and 0 as value\n",
    "    all_events_dict=dict([(event,0) for event in all_events])\n",
    "\n",
    "    if this_event_id != None:\n",
    "\n",
    "        # if event_id already in predictionModel update it by +1 to the true event\n",
    "        try:\n",
    "            predictionModel[this_event_id][event] +=1\n",
    "        # if event_id not in predictionModel, add it to the dict with the all_events_dict as key and update it by +1 tot the true event\n",
    "        except:\n",
    "            predictionModel[this_event_id] = all_events_dict\n",
    "            predictionModel[this_event_id][event] +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict: Elapsed time during the whole program in seconds: 69.234375\n"
     ]
    }
   ],
   "source": [
    "### RUNNING THE MODEL ###\n",
    "# We have to run the model line by line, we can't do things in parallel, otherwise it's not on the fly\n",
    "\n",
    "def processEvent(case, event, lifecycle, row_nr, amount=None):\n",
    "    \"\"\"\n",
    "    the input is the the raw info of a case\n",
    "    the function updates the predictionModel, caseStorage and the errorStorage\n",
    "    \"\"\"\n",
    "    #gets info of the incomming event\n",
    "    previousEvent, previousEvent_id, previousLifecycle, howManyConcurentEvents = getFeatures(case, event)\n",
    "\n",
    "    # makes the event_id based on the features and is used to make the prediction\n",
    "    event_id = str(event)+'_XX_'+str(amount)+'_XX_'+str(previousEvent)+'_XX_'+str(previousLifecycle)+'_XX_'+str(howManyConcurentEvents)\n",
    "\n",
    "    # gets the prediction of event_id from the predictionModel\n",
    "    predictedEvent = getPrediction(event_id)\n",
    "\n",
    "    # update storage\n",
    "    caseStorage[case] = [event, previousEvent, event_id, previousEvent_id, lifecycle, previousLifecycle, amount, predictedEvent, row_nr]\n",
    "\n",
    "    # update predictionModel\n",
    "    updatePredictionModel(previousEvent_id, event)\n",
    "\n",
    "\n",
    "### Run over all lines =>\n",
    "\n",
    "# Start the stopwatch / counter\n",
    "start_time = time.process_time()\n",
    "\n",
    "# running the on-the-fly model for each row\n",
    "\n",
    "[processEvent(case, event, lifecycle, row_nr, amount) for case, event, lifecycle, row_nr, amount in zip(dataset[case_column],dataset[event_column], dataset[lifecycle_column], dataset[row_nr_column], dataset[amount_column])]\n",
    "\n",
    "# Stop the stopwatch / counter\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(\"dict: Elapsed time during the whole program in seconds:\", end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:0.7989289287325657\n",
      "length df = 214377, length predictions = 214377\n"
     ]
    }
   ],
   "source": [
    "# count keeps track on how many the model was correct and divides by the amount of predictions made\n",
    "count_train=0\n",
    "predictions_index_train = []\n",
    "for key in errorStorage:\n",
    "    count_train += errorStorage[key][2]\n",
    "    predictions_index_train.append([key,errorStorage[key][3]])\n",
    "len_set_train = len(errorStorage)\n",
    "train_acc_event_otf = count_train/len_set_train\n",
    "print(f'train accuracy:{train_acc_event_otf}')\n",
    "for case in caseStorage:\n",
    "    predictions_index_train.append([caseStorage[case][8], caseStorage[case][7]])\n",
    "print(f'length df = {len(df)}, length predictions = {len(predictions_index_train)}')\n",
    "train_pred_event_otf = [x[1] for x in sorted(predictions_index_train)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:0.7673937459360407\n",
      "test accuracy:0.1403913223384761\n"
     ]
    }
   ],
   "source": [
    "places = [1, 2]\n",
    "places_dict = {}\n",
    "for place in places:\n",
    "    errorStorage = {}\n",
    "    caseStorage = {}\n",
    "    [processEvent(case, event, lifecycle, row_nr, amount) for case, event, lifecycle, row_nr, amount in zip(dataset_val[case_column],dataset_val[event_column], dataset_val[lifecycle_column], dataset_val[row_nr_column], dataset_val[amount_column])]\n",
    "\n",
    "    # count keeps track on how many the model was correct and divides by the amount of predictions made\n",
    "\n",
    "    count_val=0\n",
    "    predictions_index_val = []\n",
    "    for key in errorStorage:\n",
    "        count_val += errorStorage[key][2]\n",
    "        predictions_index_val.append([key, errorStorage[key][3]])\n",
    "    len_set_val = len(errorStorage)\n",
    "    val_acc_event_otf = count_val/len_set_val\n",
    "    print(f'test accuracy:{val_acc_event_otf}')\n",
    "    places_dict[place] = val_acc_event_otf\n",
    "place = max(places_dict, key=places_dict.get)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:0.7980754341333923\n",
      "length df = 47823, length predictions = 47823\n"
     ]
    }
   ],
   "source": [
    "# empty errorStorage and run model on test set\n",
    "errorStorage = {}\n",
    "caseStorage = {}\n",
    "[processEvent(case, event, lifecycle, row_nr, amount) for case, event, lifecycle, row_nr, amount in zip(dataset_test[case_column],dataset_test[event_column], dataset_test[lifecycle_column], dataset_test[row_nr_column], dataset_test[amount_column])]\n",
    "\n",
    "# count keeps track on how many the model was correct and divides by the amount of predictions made\n",
    "\n",
    "count_test=0\n",
    "predictions_index_test = []\n",
    "for key in errorStorage:\n",
    "    count_test += errorStorage[key][2]\n",
    "    predictions_index_test.append([key, errorStorage[key][3]])\n",
    "len_set_test = len(errorStorage)\n",
    "test_acc_event_otf = count_test/len_set_test\n",
    "print(f'test accuracy:{test_acc_event_otf}')\n",
    "for case in caseStorage:\n",
    "    predictions_index_test.append([caseStorage[case][8], caseStorage[case][7]])\n",
    "print(f'length df = {len(df_test)}, length predictions = {len(predictions_index_test)}')\n",
    "test_pred_event_otf = [x[1] for x in sorted(predictions_index_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "amount_column = 'case:AMOUNT_REQ'\n",
    "df[pred_event_otf] = train_pred_event_otf\n",
    "df_test[pred_event_otf] = test_pred_event_otf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(79.89289287325657, 79.80754341333923)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(by=[case_column, timestamp_column]).reset_index(drop=True)\n",
    "df_test = df_test.sort_values(by=[case_column, timestamp_column]).reset_index(drop=True)\n",
    "\n",
    "training_event_accuracy = len(df[(df[pred_event_otf].shift(periods=1)==df[event_column]) & (df[case_column].shift(periods=1) == df[case_column])]) * 100 / len(df[df[case_column].shift(periods=1) == df[case_column]])\n",
    "\n",
    "test_event_accuracy = len(df_test[(df_test[pred_event_otf].shift(periods=1)==df_test[event_column]) & (df_test[case_column].shift(periods=1) == df_test[case_column])]) * 100 / len(df_test[df_test[case_column].shift(periods=1) == df_test[case_column]])\n",
    "\n",
    "training_event_accuracy, test_event_accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model with: event, previousevent, previouslifecycle, howmanyconcurentevents, amount\n",
    "Accuracy test: 0.813\n",
    "\n",
    "model with: event, previousevent, previouslifecycle, howmanyconcurentevents\n",
    "Accuracy test: 0.816\n",
    "\n",
    "model with: event, previousevent, previouslifecycle, amount\n",
    "Accuracy test: 0.816\n",
    "\n",
    "model with: event, previousevent, previouslifecycle\n",
    "Accuracy test: 0.817\n",
    "\n",
    "model with: event, previousevent\n",
    "Accuracy test: 0.804"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}