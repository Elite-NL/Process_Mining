{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### IMPORT PACKAGES ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to make pretty plots\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# to play with time :-)\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', '_i', '_ii', '_iii', '_i1', 'pd', 'np', 'plotly', 'px', 'go', 'datetime', 'time', '_i2', '_i3', 'df', 'df_test', 'case_column', 'event_column', 'timestamp_column', 'timeformat_timestamp', 'lifecycle_column', 'amount_column', 'row_nr_column', 'pred_event_otf', 'amount_column_in_data', '_i4', 'all_events', '_i5', 'df_most_common_event', 'most_common_event', '_i6', 'additionalInfo', 'columns', 'dataset', 'dataset_test', '_i7', 'caseStorage', 'errorStorage', 'getFeatures', '_i8', 'predictionModel', 'getPrediction', 'updatePredictionModel', '_i9', 'processEvent', 'start_time', 'end_time', '_i10', 'count_train', 'predictions_index_train', 'key', 'len_set_train', 'train_acc_event_otf', 'case', 'train_pred_event_otf', '_i11', 'count_test', 'predictions_index_test', 'len_set_test', 'test_acc_event_otf', 'test_pred_event_otf', '_i12', 'sys', 'remove_imported_pydev_package', '_pydevd_bundle', 'pydev_jupyter_vars', '_i13', '_i14'])\n"
     ]
    }
   ],
   "source": [
    "print(globals().keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT THE DATA ###\n",
    "\n",
    "if (('df' not in globals()) or ('df_test' not in globals())):\n",
    "    ### IMPORT THE DATA ###\n",
    "    df = pd.read_csv('data/BPI_Challenge_2012-training.csv')\n",
    "    df_test = pd.read_csv('data/BPI_Challenge_2012-test.csv')\n",
    "    case_column = \"case concept:name\"\n",
    "    event_column = \"event concept:name\"\n",
    "    timestamp_column = \"event time:timestamp\"\n",
    "    timeformat_timestamp = \"%d-%m-%Y %H:%M:%S.%f\"\n",
    "    lifecycle_column = 'event lifecycle:transition'\n",
    "    amount_column = 'case AMOUNT_REQ'\n",
    "    row_nr_column = 'row_nr'\n",
    "    pred_event_otf = \"pred_event_otf\"\n",
    "\n",
    "if ('amount_column_in_data' not in globals()):\n",
    "    amount_column_in_data = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#make a list with all possible events\n",
    "all_events=list(df[event_column].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# get most common event\n",
    "df_most_common_event =pd.DataFrame(df[event_column].value_counts())\n",
    "df_most_common_event.reset_index(inplace=True)\n",
    "most_common_event = df_most_common_event.iloc[0,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_12152/2854691640.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[row_nr_column] = dataset.index\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_12152/2854691640.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_test[row_nr_column] = dataset_test.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case concept:name      event concept:name event lifecycle:transition  \\\n",
      "0             173688             A_SUBMITTED                   COMPLETE   \n",
      "1             173688       A_PARTLYSUBMITTED                   COMPLETE   \n",
      "2             173688           A_PREACCEPTED                   COMPLETE   \n",
      "3             173688  W_Completeren aanvraag                   SCHEDULE   \n",
      "4             173691             A_SUBMITTED                   COMPLETE   \n",
      "\n",
      "   case AMOUNT_REQ  row_nr  \n",
      "0            20000       0  \n",
      "1            20000       1  \n",
      "2            20000       2  \n",
      "3            20000       3  \n",
      "4                0       4  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_12152/2854691640.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[amount_column] = [round(x,-4) for x in dataset[amount_column]]\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_12152/2854691640.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_test[amount_column] = [round(x,-4) for x in dataset_test[amount_column]]\n"
     ]
    }
   ],
   "source": [
    "# additional columns that you want to include\n",
    "additionalInfo = []\n",
    "\n",
    "if amount_column_in_data == True:\n",
    "    if amount_column not in list(df):\n",
    "        amount_column = 'case RequestedAmount'\n",
    "    additionalInfo.append(amount_column)\n",
    "\n",
    "\n",
    "# make a list of the columns you need\n",
    "columns = [case_column, event_column, lifecycle_column]\n",
    "columns.extend(additionalInfo)\n",
    "\n",
    "\n",
    "# you can get rid of all the other columns, to make things faster\n",
    "\n",
    "\n",
    "dataset = df[columns]\n",
    "dataset_test = df_test[columns]\n",
    "dataset[row_nr_column] = dataset.index\n",
    "dataset_test[row_nr_column] = dataset_test.index\n",
    "\n",
    "if amount_column_in_data!=True:\n",
    "    dataset[amount_column] = [0 for i in range(len(dataset))]\n",
    "    dataset_test[amount_column] = [0 for i in range(len(dataset_test))]\n",
    "\n",
    "\n",
    "# round the amount column on 10000\n",
    "if amount_column in list(dataset):\n",
    "    dataset[amount_column] = [round(x,-4) for x in dataset[amount_column]]\n",
    "    dataset_test[amount_column] = [round(x,-4) for x in dataset_test[amount_column]]\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### STORAGE ###\n",
    "# we want to keep track of things that happen within one case\n",
    "\n",
    "# caseStorage stores: key=instance, values= [event, previousEvent, event_id, previousEvent_id, lifecycle, previousLifecycle, amount, predictedEvent]\n",
    "# to look up the previous event in this instance, and it's predicted TimePassed\n",
    "caseStorage = {}\n",
    "\n",
    "# we also want to keep track of the predictionError\n",
    "# errorStorage stores: key=unique integer, values= [previousEvent, previousLifecycle, predictionError,predictedEvent, event]\n",
    "errorStorage = {}\n",
    "\n",
    "# we also want to add a log feature => we don't have to save this seperatly, just needed to check if having it makes sense.\n",
    "# how many events of the same activty are running at the same time might be interesting\n",
    "# concurentEvents = {}\n",
    "\n",
    "def getFeatures(case, event):\n",
    "    \"\"\"\n",
    "    This function extracts extra info of incomming event from the caseStorage\n",
    "    \"\"\"\n",
    "\n",
    "    # if the case is already in storage, info of previous event is extracted from caseStorage\n",
    "    if case in caseStorage:\n",
    "\n",
    "        previousEvent = caseStorage[case][0]\n",
    "        previousLifecycle = caseStorage[case][4]\n",
    "        predictedEvent = caseStorage[case][7]\n",
    "        previousEvent_id = caseStorage[case][2]\n",
    "        previousRow_nr = caseStorage[case][8]\n",
    "\n",
    "        # if prediction of previous event is correct, change predictionError to 1 and add the event to errorstorage\n",
    "        if predictedEvent == event:\n",
    "            predictionError = 1\n",
    "        else:\n",
    "            predictionError = 0\n",
    "        errorStorage[previousRow_nr] = [previousEvent, previousLifecycle, predictionError,predictedEvent, event]\n",
    "\n",
    "    # if it is a new case set info of previous event to None\n",
    "    else:\n",
    "        previousEvent = None\n",
    "        previousEvent_id = None\n",
    "        previousLifecycle = None\n",
    "\n",
    "    #if event in eventList:\n",
    "        # you want to find how many times this activity occurs without any additional information\n",
    "        #howManyConcurentEvents = [x[0] for x in caseStorage.values()].count(event)\n",
    "    #else:\n",
    "        #howManyConcurentEvents = ''\n",
    "\n",
    "    howManyConcurentEvents = round([x[0] for x in caseStorage.values()].count(event)/200)*200\n",
    "    #howManyConcurentEvents= ''\n",
    "\n",
    "    return previousEvent, previousEvent_id, previousLifecycle, howManyConcurentEvents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### THE MODEL ###\n",
    "# We start with only one feature: the historical average time between two events based on the previous event\n",
    "# You don't need a second model for the test set, since you train your model on the training-set and then use it on the test-set\n",
    "\n",
    "predictionModel = {}\n",
    "\n",
    "def getPrediction(event_id):\n",
    "    \"\"\"\n",
    "    gets the prediction of a certain event_id\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # get the event of an event_id with the highest occurrence\n",
    "        return max(predictionModel[event_id],key=predictionModel[event_id].get)\n",
    "\n",
    "    except:\n",
    "        # if event_id not in predictionModel return the most frequent event in train data as prediction\n",
    "        return most_common_event\n",
    "\n",
    "\n",
    "\n",
    "def updatePredictionModel(this_event_id, event):\n",
    "    \"\"\"\n",
    "    updates PredictionModel with the true event of a event_id\n",
    "    \"\"\"\n",
    "    # makes dict with all events as key and 0 as value\n",
    "    all_events_dict=dict([(event,0) for event in all_events])\n",
    "\n",
    "    if this_event_id != None:\n",
    "\n",
    "        # if event_id already in predictionModel update it by +1 to the true event\n",
    "        try:\n",
    "            predictionModel[this_event_id][event] +=1\n",
    "        # if event_id not in predictionModel, add it to the dict with the all_events_dict as key and update it by +1 tot the true event\n",
    "        except:\n",
    "            predictionModel[this_event_id] = all_events_dict\n",
    "            predictionModel[this_event_id][event] +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict: Elapsed time during the whole program in seconds: 97.0\n"
     ]
    }
   ],
   "source": [
    "### RUNNING THE MODEL ###\n",
    "# We have to run the model line by line, we can't do things in parallel, otherwise it's not on the fly\n",
    "\n",
    "def processEvent(case, event, lifecycle, row_nr, amount=None):\n",
    "    \"\"\"\n",
    "    the input is the the raw info of a case\n",
    "    the function updates the predictionModel, caseStorage and the errorStorage\n",
    "    \"\"\"\n",
    "    #gets info of the incomming event\n",
    "    previousEvent, previousEvent_id, previousLifecycle, howManyConcurentEvents = getFeatures(case, event)\n",
    "\n",
    "    # makes the event_id based on the features and is used to make the prediction\n",
    "    event_id = str(event)+'_XX_'+str(amount)+'_XX_'+str(previousEvent)+'_XX_'+str(previousLifecycle)+'_XX_'+str(howManyConcurentEvents)\n",
    "\n",
    "    # gets the prediction of event_id from the predictionModel\n",
    "    predictedEvent = getPrediction(event_id)\n",
    "\n",
    "    # update storage\n",
    "    caseStorage[case] = [event, previousEvent, event_id, previousEvent_id, lifecycle, previousLifecycle, amount, predictedEvent, row_nr]\n",
    "\n",
    "    # update predictionModel\n",
    "    updatePredictionModel(previousEvent_id, event)\n",
    "\n",
    "\n",
    "### Run over all lines =>\n",
    "\n",
    "# Start the stopwatch / counter\n",
    "start_time = time.process_time()\n",
    "\n",
    "# running the on-the-fly model for each row\n",
    "\n",
    "[processEvent(case, event, lifecycle, row_nr, amount) for case, event, lifecycle, row_nr, amount in zip(dataset[case_column],dataset[event_column], dataset[lifecycle_column], dataset[row_nr_column], dataset[amount_column])]\n",
    "\n",
    "# Stop the stopwatch / counter\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(\"dict: Elapsed time during the whole program in seconds:\", end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:0.8056182199815604\n",
      "length df = 214377, length predictions = 214377\n"
     ]
    }
   ],
   "source": [
    "# count keeps track on how many the model was correct and divides by the amount of predictions made\n",
    "count_train=0\n",
    "predictions_index_train = []\n",
    "for key in errorStorage:\n",
    "    count_train += errorStorage[key][2]\n",
    "    predictions_index_train.append([key,errorStorage[key][3]])\n",
    "len_set_train = len(errorStorage)\n",
    "train_acc_event_otf = count_train/len_set_train\n",
    "print(f'train accuracy:{train_acc_event_otf}')\n",
    "for case in caseStorage:\n",
    "    predictions_index_train.append([caseStorage[case][8], caseStorage[case][7]])\n",
    "print(f'length df = {len(df)}, length predictions = {len(predictions_index_train)}')\n",
    "train_pred_event_otf = [x[1] for x in sorted(predictions_index_train)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:0.8132507465988276\n",
      "length df = 47823, length predictions = 47823\n"
     ]
    }
   ],
   "source": [
    "# empty errorStorage and run model on test set\n",
    "errorStorage = {}\n",
    "caseStorage = {}\n",
    "[processEvent(case, event, lifecycle, row_nr, amount) for case, event, lifecycle, row_nr, amount in zip(dataset_test[case_column],dataset_test[event_column], dataset_test[lifecycle_column], dataset_test[row_nr_column], dataset[amount_column])]\n",
    "\n",
    "# count keeps track on how many the model was correct and divides by the amount of predictions made\n",
    "\n",
    "count_test=0\n",
    "predictions_index_test = []\n",
    "for key in errorStorage:\n",
    "    count_test += errorStorage[key][2]\n",
    "    predictions_index_test.append([key, errorStorage[key][3]])\n",
    "len_set_test = len(errorStorage)\n",
    "test_acc_event_otf = count_test/len_set_test\n",
    "print(f'test accuracy:{test_acc_event_otf}')\n",
    "for case in caseStorage:\n",
    "    predictions_index_test.append([caseStorage[case][8], caseStorage[case][7]])\n",
    "print(f'length df = {len(df_test)}, length predictions = {len(predictions_index_test)}')\n",
    "test_pred_event_otf = [x[1] for x in sorted(predictions_index_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "amount_column = 'case AMOUNT_REQ'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "model with: event, previousevent, previouslifecycle, howmanyconcurentevents, amount\n",
    "Accuracy test: 0.813\n",
    "\n",
    "model with: event, previousevent, previouslifecycle, howmanyconcurentevents\n",
    "Accuracy test: 0.816\n",
    "\n",
    "model with: event, previousevent, previouslifecycle, amount\n",
    "Accuracy test: 0.816\n",
    "\n",
    "model with: event, previousevent, previouslifecycle\n",
    "Accuracy test: 0.817\n",
    "\n",
    "model with: event, previousevent\n",
    "Accuracy test: 0.804"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}