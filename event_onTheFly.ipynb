{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### IMPORT PACKAGES ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# to make pretty plots\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# to play with time :-)\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['__name__', '__doc__', '__package__', '__loader__', '__spec__', '__builtin__', '__builtins__', '_ih', '_oh', '_dh', 'In', 'Out', 'get_ipython', 'exit', 'quit', '_', '__', '___', 'DataFrame', 'MultiIndex', 'print_columns', '_i', '_ii', '_iii', '_i1', '_1', 'sys', 'remove_imported_pydev_package', '_pydevd_bundle', 'pydev_jupyter_vars', '_i2', '_i3', '_3', '_i4', '_4', '_i5', '_i6', '_6', '_i7', 'pd', 'np', 'plotly', 'px', 'go', 'datetime', 'time', '_i8', '_8', '_i9', 'df', 'df_test', 'case_column', 'event_column', 'timestamp_column', 'timeformat_timestamp', 'lifecycle_column', 'amount_column', 'row_nr_column', 'pred_event_otf', '_i10'])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT THE DATA ###\n",
    "\n",
    "if (('df' not in globals()) or ('df_test' not in globals())):\n",
    "    ### IMPORT THE DATA ###\n",
    "    df = pd.read_csv('data/BPI_Challenge_2012-training.csv')\n",
    "    df_test = pd.read_csv('data/BPI_Challenge_2012-test.csv')\n",
    "\n",
    "# Defining database-specific variables\n",
    "case_column = \"case concept:name\"\n",
    "event_column = \"event concept:name\"\n",
    "timestamp_column = \"event time:timestamp\"\n",
    "timeformat_timestamp = \"%d-%m-%Y %H:%M:%S.%f\"\n",
    "lifecycle_column = 'event lifecycle:transition'\n",
    "amount_column = 'case AMOUNT_REQ'\n",
    "row_nr_column = 'row_nr'\n",
    "pred_event_otf = \"pred_event_otf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "outputs": [],
   "source": [
    "#make a list with all possible events\n",
    "all_events=list(df[event_column].unique())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "outputs": [],
   "source": [
    "# get most common event\n",
    "df_most_common_event =pd.DataFrame(df[event_column].value_counts())\n",
    "df_most_common_event.reset_index(inplace=True)\n",
    "most_common_event = df_most_common_event.iloc[0,0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_13112/3993958697.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[row_nr_column] = dataset.index\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_13112/3993958697.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_test[row_nr_column] = dataset_test.index\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_13112/3993958697.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset[amount_column] = [round(x,-4) for x in dataset[amount_column]]\n",
      "C:\\Users\\20203666\\AppData\\Local\\Temp/ipykernel_13112/3993958697.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset_test[amount_column] = [round(x,-4) for x in dataset_test[amount_column]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   case concept:name      event concept:name event lifecycle:transition  \\\n",
      "0             173688             A_SUBMITTED                   COMPLETE   \n",
      "1             173688       A_PARTLYSUBMITTED                   COMPLETE   \n",
      "2             173688           A_PREACCEPTED                   COMPLETE   \n",
      "3             173688  W_Completeren aanvraag                   SCHEDULE   \n",
      "4             173691             A_SUBMITTED                   COMPLETE   \n",
      "\n",
      "   case AMOUNT_REQ  row_nr  \n",
      "0            20000       0  \n",
      "1            20000       1  \n",
      "2            20000       2  \n",
      "3            20000       3  \n",
      "4                0       4  \n"
     ]
    }
   ],
   "source": [
    "# additional columns that you want to include\n",
    "additionalInfo = [amount_column]\n",
    "\n",
    "# events that are influenced by concurency\n",
    "eventList = ['A_SUBMITTED', 'A_PARTLYSUBMITTED', 'A_PREACCEPTED', 'O_SELECTED', 'A_FINALIZED', 'O_ACCEPTED']\n",
    "\n",
    "# make a list of the columns you need\n",
    "columns = [case_column, event_column, lifecycle_column]\n",
    "columns.extend(additionalInfo)\n",
    "\n",
    "\n",
    "# you can get rid of all the other columns, to make things faster\n",
    "dataset = df[columns]\n",
    "dataset_test = df_test[columns]\n",
    "dataset[row_nr_column] = dataset.index\n",
    "dataset_test[row_nr_column] = dataset_test.index\n",
    "\n",
    "# round the amount column on 10000\n",
    "if amount_column in list(dataset):\n",
    "    dataset[amount_column] = [round(x,-4) for x in dataset[amount_column]]\n",
    "    dataset_test[amount_column] = [round(x,-4) for x in dataset_test[amount_column]]\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### STORAGE ###\n",
    "# we want to keep track of things that happen within one case\n",
    "\n",
    "# caseStorage stores: key=instance, values= [event, previousEvent, event_id, previousEvent_id, lifecycle, previousLifecycle, amount, predictedEvent]\n",
    "# to look up the previous event in this instance, and it's predicted TimePassed\n",
    "caseStorage = {}\n",
    "\n",
    "# we also want to keep track of the predictionError\n",
    "# errorStorage stores: key=unique integer, values= [previousEvent, previousLifecycle, predictionError,predictedEvent, event]\n",
    "errorStorage = {}\n",
    "\n",
    "# we also want to add a log feature => we don't have to save this seperatly, just needed to check if having it makes sense.\n",
    "# how many events of the same activty are running at the same time might be interesting\n",
    "# concurentEvents = {}\n",
    "\n",
    "def getFeatures(case, event):\n",
    "    \"\"\"\n",
    "    This function extracts extra info of incomming event from the caseStorage\n",
    "    \"\"\"\n",
    "\n",
    "    # if the case is already in storage, info of previous event is extracted from caseStorage\n",
    "    if case in caseStorage:\n",
    "\n",
    "        previousEvent = caseStorage[case][0]\n",
    "        previousLifecycle = caseStorage[case][4]\n",
    "        predictedEvent = caseStorage[case][7]\n",
    "        previousEvent_id = caseStorage[case][2]\n",
    "        previousRow_nr = caseStorage[case][8]\n",
    "\n",
    "        # if prediction of previous event is correct, change predictionError to 1 and add the event to errorstorage\n",
    "        if predictedEvent == event:\n",
    "            predictionError = 1\n",
    "        else:\n",
    "            predictionError = 0\n",
    "        errorStorage[previousRow_nr] = [previousEvent, previousLifecycle, predictionError,predictedEvent, event]\n",
    "\n",
    "    # if it is a new case set info of previous event to None\n",
    "    else:\n",
    "        previousEvent = None\n",
    "        previousEvent_id = None\n",
    "        previousLifecycle = None\n",
    "\n",
    "    if event in eventList:\n",
    "        # you want to find how many times this activity occurs without any additional information\n",
    "        howManyConcurentEvents = [x[0] for x in caseStorage.values()].count(event)\n",
    "    else:\n",
    "        howManyConcurentEvents = ''\n",
    "\n",
    "    return previousEvent, previousEvent_id, previousLifecycle, howManyConcurentEvents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### THE MODEL ###\n",
    "# We start with only one feature: the historical average time between two events based on the previous event\n",
    "# You don't need a second model for the test set, since you train your model on the training-set and then use it on the test-set\n",
    "\n",
    "predictionModel = {}\n",
    "\n",
    "def getPrediction(event_id):\n",
    "    \"\"\"\n",
    "    gets the prediction of a certain event_id\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # get the event of an event_id with the highest occurrence\n",
    "        return max(predictionModel[event_id],key=predictionModel[event_id].get)\n",
    "\n",
    "    except:\n",
    "        # if event_id not in predictionModel return the most frequent event in train data as prediction\n",
    "        return most_common_event\n",
    "\n",
    "\n",
    "\n",
    "def updatePredictionModel(this_event_id, event):\n",
    "    \"\"\"\n",
    "    updates PredictionModel with the true event of a event_id\n",
    "    \"\"\"\n",
    "    # makes dict with all events as key and 0 as value\n",
    "    all_events_dict=dict([(event,0) for event in all_events])\n",
    "\n",
    "    if this_event_id != None:\n",
    "\n",
    "        # if event_id already in predictionModel update it by +1 to the true event\n",
    "        try:\n",
    "            predictionModel[this_event_id][event] +=1\n",
    "        # if event_id not in predictionModel, add it to the dict with the all_events_dict as key and update it by +1 tot the true event\n",
    "        except:\n",
    "            predictionModel[this_event_id] = all_events_dict\n",
    "            predictionModel[this_event_id][event] +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict: Elapsed time during the whole program in seconds: 18.421875\n"
     ]
    }
   ],
   "source": [
    "### RUNNING THE MODEL ###\n",
    "# We have to run the model line by line, we can't do things in parallel, otherwise it's not on the fly\n",
    "\n",
    "def processEvent(case, event, lifecycle, row_nr, amount=None):\n",
    "    \"\"\"\n",
    "    the input is the the raw info of a case\n",
    "    the function updates the predictionModel, caseStorage and the errorStorage\n",
    "    \"\"\"\n",
    "    #gets info of the incomming event\n",
    "    previousEvent, previousEvent_id, previousLifecycle, howManyConcurentEvents = getFeatures(case, event)\n",
    "\n",
    "    # makes the event_id based on the features and is used to make the prediction\n",
    "    event_id = str(event)+'_XX_'+str(amount)+'_XX_'+str(previousEvent)+'_XX_'+str(previousLifecycle)+'_XX_'+str(howManyConcurentEvents)\n",
    "\n",
    "    # gets the prediction of event_id from the predictionModel\n",
    "    predictedEvent = getPrediction(event_id)\n",
    "\n",
    "    # update storage\n",
    "    caseStorage[case] = [event, previousEvent, event_id, previousEvent_id, lifecycle, previousLifecycle, amount, predictedEvent, row_nr]\n",
    "\n",
    "    # update predictionModel\n",
    "    updatePredictionModel(previousEvent_id, event)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Run over all lines =>\n",
    "\n",
    "# Start the stopwatch / counter\n",
    "start_time = time.process_time()\n",
    "\n",
    "# running the on-the-fly model for each row\n",
    "\n",
    "[processEvent(case, event, lifecycle, row_nr, amount) for case, event, lifecycle, row_nr, amount in zip(dataset[case_column],dataset[event_column], dataset[lifecycle_column], dataset[row_nr_column], dataset[amount_column])]\n",
    "\n",
    "# Stop the stopwatch / counter\n",
    "end_time = time.process_time()\n",
    "\n",
    "print(\"dict: Elapsed time during the whole program in seconds:\", end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy:0.8166329913490398\n",
      "length df = 214377, length predictions = 214377\n"
     ]
    }
   ],
   "source": [
    "# count keeps track on how many the model was correct and divides by the amount of predictions made\n",
    "count_train=0\n",
    "predictions_index_train = []\n",
    "for key in errorStorage:\n",
    "    count_train += errorStorage[key][2]\n",
    "    predictions_index_train.append([key,errorStorage[key][3]])\n",
    "len_set_train = len(errorStorage)\n",
    "train_acc_event_otf = count_train/len_set_train\n",
    "print(f'train accuracy:{train_acc_event_otf}')\n",
    "for case in caseStorage:\n",
    "    predictions_index_train.append([caseStorage[case][8], None])\n",
    "print(f'length df = {len(df)}, length predictions = {len(predictions_index_train)}')\n",
    "train_pred_event_otf = [x[1] for x in sorted(predictions_index_train)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy:0.8156398628470302\n",
      "length df = 47823, length predictions = 47823\n"
     ]
    }
   ],
   "source": [
    "# empty errorStorage and run model on test set\n",
    "errorStorage = {}\n",
    "caseStorage = {}\n",
    "[processEvent(case, event, lifecycle, row_nr, amount) for case, event, lifecycle, row_nr, amount in zip(dataset_test[case_column],dataset_test[event_column], dataset_test[lifecycle_column], dataset_test[row_nr_column], dataset[amount_column])]\n",
    "\n",
    "# count keeps track on how many the model was correct and divides by the amount of predictions made\n",
    "\n",
    "count_test=0\n",
    "predictions_index_test = []\n",
    "for key in errorStorage:\n",
    "    count_test += errorStorage[key][2]\n",
    "    predictions_index_test.append([key, errorStorage[key][3]])\n",
    "len_set_test = len(errorStorage)\n",
    "test_acc_event_otf = count_test/len_set_test\n",
    "print(f'test accuracy:{test_acc_event_otf}')\n",
    "for case in caseStorage:\n",
    "    predictions_index_test.append([caseStorage[case][8], None])\n",
    "print(f'length df = {len(df_test)}, length predictions = {len(predictions_index_test)}')\n",
    "test_pred_event_otf = [x[1] for x in sorted(predictions_index_test)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "data": {
      "text/plain": "             eventID   case concept:name                  case REG_DATE  \\\n0      44964012621824             206324  2012-02-03T17:17:11.047+01:00   \n1      44964012621825             206324  2012-02-03T17:17:11.047+01:00   \n2      44964012621826             206324  2012-02-03T17:17:11.047+01:00   \n3      44968307589120             206327  2012-02-03T17:23:41.949+01:00   \n4      44968307589121             206327  2012-02-03T17:23:41.949+01:00   \n...               ...                ...                            ...   \n47818  54666343743523             213276  2012-02-27T14:12:41.868+01:00   \n47819  54666343743524             213276  2012-02-27T14:12:41.868+01:00   \n47820  49495203119136             209595  2012-02-15T10:10:36.503+01:00   \n47821  52342766436386             211624  2012-02-21T23:38:40.044+01:00   \n47822  52342766436387             211624  2012-02-21T23:38:40.044+01:00   \n\n       case AMOUNT_REQ              event concept:name  \\\n0                    0                     A_SUBMITTED   \n1                    0               A_PARTLYSUBMITTED   \n2                    0                      A_DECLINED   \n3                10000                     A_SUBMITTED   \n4                10000               A_PARTLYSUBMITTED   \n...                ...                             ...   \n47818            20000  W_Nabellen incomplete dossiers   \n47819            20000  W_Nabellen incomplete dossiers   \n47820            10000             W_Nabellen offertes   \n47821            40000  W_Nabellen incomplete dossiers   \n47822            40000  W_Nabellen incomplete dossiers   \n\n      event lifecycle:transition     event time:timestamp  \\\n0                       COMPLETE  03-02-2012 17:17:11.047   \n1                       COMPLETE  03-02-2012 17:17:11.323   \n2                       COMPLETE  03-02-2012 17:17:42.964   \n3                       COMPLETE  03-02-2012 17:23:41.949   \n4                       COMPLETE  03-02-2012 17:23:42.504   \n...                          ...                      ...   \n47818                      START  14-03-2012 15:59:28.309   \n47819                   COMPLETE  14-03-2012 16:00:09.680   \n47820                      START  14-03-2012 16:02:03.883   \n47821                      START  14-03-2012 16:04:46.192   \n47822                   COMPLETE  14-03-2012 16:04:54.681   \n\n                                 pred                  pred_event_otf  \n0                   A_PARTLYSUBMITTED               A_PARTLYSUBMITTED  \n1                       A_PREACCEPTED                   A_PREACCEPTED  \n2                                None                            None  \n3                   A_PARTLYSUBMITTED               A_PARTLYSUBMITTED  \n4                  W_Afhandelen leads              W_Afhandelen leads  \n...                               ...                             ...  \n47818  W_Nabellen incomplete dossiers  W_Nabellen incomplete dossiers  \n47819                            None                            None  \n47820                            None                            None  \n47821  W_Nabellen incomplete dossiers  W_Nabellen incomplete dossiers  \n47822                            None                            None  \n\n[47823 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eventID</th>\n      <th>case concept:name</th>\n      <th>case REG_DATE</th>\n      <th>case AMOUNT_REQ</th>\n      <th>event concept:name</th>\n      <th>event lifecycle:transition</th>\n      <th>event time:timestamp</th>\n      <th>pred</th>\n      <th>pred_event_otf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44964012621824</td>\n      <td>206324</td>\n      <td>2012-02-03T17:17:11.047+01:00</td>\n      <td>0</td>\n      <td>A_SUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>03-02-2012 17:17:11.047</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>A_PARTLYSUBMITTED</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44964012621825</td>\n      <td>206324</td>\n      <td>2012-02-03T17:17:11.047+01:00</td>\n      <td>0</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>03-02-2012 17:17:11.323</td>\n      <td>A_PREACCEPTED</td>\n      <td>A_PREACCEPTED</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44964012621826</td>\n      <td>206324</td>\n      <td>2012-02-03T17:17:11.047+01:00</td>\n      <td>0</td>\n      <td>A_DECLINED</td>\n      <td>COMPLETE</td>\n      <td>03-02-2012 17:17:42.964</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44968307589120</td>\n      <td>206327</td>\n      <td>2012-02-03T17:23:41.949+01:00</td>\n      <td>10000</td>\n      <td>A_SUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>03-02-2012 17:23:41.949</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>A_PARTLYSUBMITTED</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44968307589121</td>\n      <td>206327</td>\n      <td>2012-02-03T17:23:41.949+01:00</td>\n      <td>10000</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>03-02-2012 17:23:42.504</td>\n      <td>W_Afhandelen leads</td>\n      <td>W_Afhandelen leads</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47818</th>\n      <td>54666343743523</td>\n      <td>213276</td>\n      <td>2012-02-27T14:12:41.868+01:00</td>\n      <td>20000</td>\n      <td>W_Nabellen incomplete dossiers</td>\n      <td>START</td>\n      <td>14-03-2012 15:59:28.309</td>\n      <td>W_Nabellen incomplete dossiers</td>\n      <td>W_Nabellen incomplete dossiers</td>\n    </tr>\n    <tr>\n      <th>47819</th>\n      <td>54666343743524</td>\n      <td>213276</td>\n      <td>2012-02-27T14:12:41.868+01:00</td>\n      <td>20000</td>\n      <td>W_Nabellen incomplete dossiers</td>\n      <td>COMPLETE</td>\n      <td>14-03-2012 16:00:09.680</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>47820</th>\n      <td>49495203119136</td>\n      <td>209595</td>\n      <td>2012-02-15T10:10:36.503+01:00</td>\n      <td>10000</td>\n      <td>W_Nabellen offertes</td>\n      <td>START</td>\n      <td>14-03-2012 16:02:03.883</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>47821</th>\n      <td>52342766436386</td>\n      <td>211624</td>\n      <td>2012-02-21T23:38:40.044+01:00</td>\n      <td>40000</td>\n      <td>W_Nabellen incomplete dossiers</td>\n      <td>START</td>\n      <td>14-03-2012 16:04:46.192</td>\n      <td>W_Nabellen incomplete dossiers</td>\n      <td>W_Nabellen incomplete dossiers</td>\n    </tr>\n    <tr>\n      <th>47822</th>\n      <td>52342766436387</td>\n      <td>211624</td>\n      <td>2012-02-21T23:38:40.044+01:00</td>\n      <td>40000</td>\n      <td>W_Nabellen incomplete dossiers</td>\n      <td>COMPLETE</td>\n      <td>14-03-2012 16:04:54.681</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>47823 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[pred_event_otf] = train_pred_event_otf\n",
    "df_test[pred_event_otf] = test_pred_event_otf\n",
    "df_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}