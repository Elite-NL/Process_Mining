{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook can be run separately from the deliverable tool.\n",
    "if (('df' not in globals()) or ('df_test' not in globals())):\n",
    "    df = pd.read_csv('data/BPI_Challenge_2012-training.csv')\n",
    "    \n",
    "    df_test = pd.read_csv('data/BPI_Challenge_2012-test.csv')\n",
    "\n",
    "    # Defining database-specific variables\n",
    "    case_column = \"case concept:name\"\n",
    "    registration_time_column = \"case REG_DATE\"\n",
    "    event_column = \"event concept:name\"\n",
    "    timestamp_column = \"event time:timestamp\"\n",
    "    timeformat_registration = \"%Y-%m-%dT%H:%M:%S\" # new time format\n",
    "    timeformat_timestamp = \"%d-%m-%Y %H:%M:%S.%f\"\n",
    "\n",
    "    # Names of columns we will add in this notebook\n",
    "    position_column = \"Position\"\n",
    "    baseline_next_event_column = \"Baseline Prediction for Next Activity\"\n",
    "    baseline_next_timestamp_column = \"Baseline Prediction for Next Timestamp\"\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data preprocessing of the timestamps\n",
    "df[registration_time_column]= [re.sub('\\..*|\\+.*','',a,flags=re.DOTALL) for a in df[registration_time_column]]\n",
    "df[registration_time_column] = [datetime.strptime(date, timeformat_registration) for date in df[registration_time_column]]\n",
    "df[timestamp_column] = [datetime.strptime(date, timeformat_timestamp) for date in df[timestamp_column]]\n",
    "df = df.sort_values(by=[case_column, timestamp_column]).reset_index() # sort values by user and time of event\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data preprocessing of the timestamps\n",
    "df_test[registration_time_column]= [re.sub('\\..*|\\+.*','',a,flags=re.DOTALL) for a in df_test[registration_time_column]]\n",
    "df_test[registration_time_column] = [datetime.strptime(date, timeformat_registration) for date in df_test[registration_time_column]]\n",
    "df_test[timestamp_column] = [datetime.strptime(date, timeformat_timestamp) for date in df_test[timestamp_column]]\n",
    "df_test = df_test.sort_values(by=[case_column, timestamp_column]).reset_index() # sort values by user and time of event\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill in the Position column that shows which position is a certain event in the trace (the first event is 1)\n",
    "df[position_column] = df.groupby([case_column]).cumcount()+1\n",
    "df_test[position_column] = df_test.groupby([case_column]).cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Explanation: We subtract the timestamps and then shift the results up so the difference from n to n+1 is on row n.\n",
    "# Only if both events are in the same trace should include the row in the mean() calculation.\n",
    "shifted_deltatimes = df[timestamp_column].diff().shift(periods=-1)[df[case_column].shift(periods=-1) == df[case_column]]\n",
    "\n",
    "# The mean() function will return NaT if the input is empty, we replace this with pd.Timedelta(0)\n",
    "def replacenat(timedelta):\n",
    "    if (pd.isna(timedelta)):\n",
    "        return pd.Timedelta(0)\n",
    "    else:\n",
    "        return timedelta\n",
    "\n",
    "# list of unique events in the data\n",
    "unique_events = df[event_column].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store the most common (mode) event following the key event\n",
    "dict_common_next_event = {event: df[(df[case_column].shift(periods=-1) == df[case_column]) & (df[event_column].shift(periods=1) == event)][event_column].mode()[0] for event in unique_events}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We apply the dictionary to the dataset to get the baseline event prediction\n",
    "df[baseline_next_event_column] = [(dict_common_next_event[event] if (event in dict_common_next_event) else \"-\") for event in df[event_column]]\n",
    "\n",
    "df[df[case_column] == 185548]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store the average time for each event\n",
    "dict_time_per_event = {event: replacenat(shifted_deltatimes[df[event_column] == event].mean()) for event in unique_events}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the average time to the dataframe to get the baseline time prediction\n",
    "df[baseline_next_timestamp_column] = [(time + dict_time_per_event[event] if (event in dict_time_per_event) else time) for event,time in zip(df[event_column], df[timestamp_column])]\n",
    "\n",
    "df[df[case_column] == 185548]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the baseline predictions to the test dataset\n",
    "df_test[baseline_next_event_column] = [(dict_common_next_event[event] if (event in dict_common_next_event) else \"-\") for event in df_test[event_column]]\n",
    "\n",
    "df_test[baseline_next_timestamp_column] = [(time + dict_time_per_event[event] if (event in dict_time_per_event) else time) for event,time in zip(df_test[event_column], df_test[timestamp_column])]\n",
    "\n",
    "df_test[df_test[case_column] == 206327]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy % of event predictions:\n",
    "\n",
    "training_event_accuracy = len(df[(df[baseline_next_event_column].shift(periods=1)==df[event_column]) & (df[case_column].shift(periods=1) == df[case_column])]) * 100 / len(df[df[case_column].shift(periods=1) == df[case_column]])\n",
    "\n",
    "test_event_accuracy = len(df_test[(df_test[baseline_next_event_column].shift(periods=1)==df_test[event_column]) & (df_test[case_column].shift(periods=1) == df_test[case_column])]) * 100 / len(df_test[df_test[case_column].shift(periods=1) == df_test[case_column]])\n",
    "\n",
    "training_event_accuracy, test_event_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Absolute Error of time predictions:\n",
    "\n",
    "training_time_MAE = abs(df[timestamp_column] - df[baseline_next_timestamp_column].shift(periods=1))[df[case_column].shift(periods=1) == df[case_column]].mean()\n",
    "\n",
    "test_time_MAE = abs(df_test[timestamp_column] - df_test[baseline_next_timestamp_column].shift(periods=1))[df_test[case_column].shift(periods=1) == df_test[case_column]].mean()\n",
    "\n",
    "training_time_MAE, test_time_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "450e333e9284914ea1fdff9838c0f3ff8e2f8f37f2f7a4d8dce33ea62376eaf6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
