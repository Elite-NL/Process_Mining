{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467d48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTES ###\n",
    "\n",
    "# 2012 works with both feature spaces\n",
    "# 2012 WORKS ON FEATURE SPACE 1: TEST ACCURACY = 0.5483\n",
    "# 2012 WORKS ON FEATURE SPACE 2: TEST ACCURACY = 0.7370\n",
    "\n",
    "# created test features for 2017\n",
    "# created train features for 2017\n",
    "# 2017 WORKS ON FEATURE SPACE 1: TEST ACCURACY = 0.4813\n",
    "# 2017 WORKS ON FEATURE SPACE 2: TEST ACCURACY = 0.3642\n",
    "\n",
    "# 2018 - when you read the csv, it requires encoding = latin-1\n",
    "# 2018 WORKS ON FEATURE SPACE 1: TEST ACCURACY = 0.2792\n",
    "# 2018 WORKS ON FEATURE SPACE 2: TEST ACCURACY = 0.1995\n",
    "# created train features for 2018\n",
    "# created test features for 2018\n",
    "\n",
    "# ROAD FINES WORKS ON FEATURE SPACE 1: TEST ACCURACY = 0.8622\n",
    "# ROAD FINES WORKS ON FEATURE SPACE 2: TEST ACCURACY = 0.8593\n",
    "# created test features for road fines\n",
    "# created train features for road fines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbf924",
   "metadata": {},
   "source": [
    "# !!!!! IF YOU WANT TO RUN THE NOTEBOOK, ADD TO YOUR data FOLDER added_features_event_log_update_train.csv FROM GOOGLE DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242c4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT PACKAGES ###\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# process mining for python\n",
    "import pm4py\n",
    "\n",
    "# machine learning\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# nice plots & tables\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# to make a counter object\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f15a1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining database-specific variables\n",
    "\n",
    "case_column = \"case concept:name\"\n",
    "lifecycle_column = 'event lifecycle:transition'\n",
    "event_column = \"event concept:name\"\n",
    "timestamp_column = \"event time:timestamp\"\n",
    "position_column = \"position\"\n",
    "req_amount_column = 'case AMOUNT_REQ'\n",
    "previous_event_column = 'previous_event'\n",
    "previous_lifecycle_column = 'previous lifecycle'\n",
    "previous_position_column = 'previous_position'\n",
    "day_of_year_column = \"day_of_year\"\n",
    "started_today_column = \"started_today\"\n",
    "prev_started_today_column = 'previous_started_today'\n",
    "timeformat_timestamp = '%Y-%m-%d %H:%M:%S.%f'\n",
    "most_common_column = 'most_common_event_name'\n",
    "previous_most_common_column = 'previous_most_common_event_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b500dfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### IMPORT CSV FUNCTION ###\n",
    "\n",
    "def import_csv(file_path):\n",
    "    try:\n",
    "        event_log = pd.read_csv(file_path, sep=',')\n",
    "    except:\n",
    "        event_log = pd.read_csv(file_path, sep=',', encoding = 'latin-1')\n",
    "    # make a timestamp out of the timefield\n",
    "    try:\n",
    "        event_log[timestamp_column] = [datetime.strptime(date, timeformat_timestamp) for date in event_log[timestamp_column]]\n",
    "    except:\n",
    "        try:\n",
    "            event_log[timestamp_column] = [datetime.strptime(date, \"%d-%m-%Y %H:%M:%S.%f\") for date in event_log[timestamp_column]]\n",
    "        except:\n",
    "            event_log[timestamp_column] = [datetime.strptime(date, \"%Y-%m-%d\") for date in event_log[timestamp_column]]\n",
    "    event_log = event_log.sort_values(by=[timestamp_column])  # sort values by user and time of event\n",
    "\n",
    "\n",
    "    # replace nan with 0:\n",
    "    event_log = event_log.fillna(0)\n",
    "\n",
    "    # change format into pm4py event_log\n",
    "    event_log = pm4py.format_dataframe(event_log, case_id = case_column, activity_key = event_column,\n",
    "                                       timestamp_key = timestamp_column, timest_format = '%Y-%m-%d %H:%M:%Sz')\n",
    "\n",
    "    #2011-10-01T00:38:44.546+02:00\n",
    "    # print what the start and end activities are:\n",
    "    start_activities = pm4py.get_start_activities(event_log)\n",
    "    end_activities = pm4py.get_end_activities(event_log)\n",
    "    print(\"Start activities: {}\\n\\nEnd activities: {}\".format(start_activities, end_activities))\n",
    "\n",
    "    # print how many events and how many instances (cases) there are\n",
    "    num_events = len(event_log)\n",
    "    num_cases = len(event_log[case_column].unique())\n",
    "    print(' ')\n",
    "    print(\"Number of events: {}\\nNumber of cases: {}\".format(num_events, num_cases))\n",
    "\n",
    "\n",
    "    return event_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36acb65",
   "metadata": {},
   "source": [
    "# MAKE SURE THAT YOU CHANGE THIS DEPENDING ON THE USED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c141430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012 = False\n",
    "added_features = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5ba8022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start activities: {'A_SUBMITTED': 10469}\n",
      "\n",
      "End activities: {'A_DECLINED': 2690, 'W_Valideren aanvraag': 2293, 'W_Afhandelen leads': 1846, 'W_Completeren aanvraag': 1473, 'W_Nabellen offertes': 905, 'A_CANCELLED': 602, 'W_Nabellen incomplete dossiers': 338, 'O_CANCELLED': 268, 'W_Beoordelen fraude': 49, 'W_Wijzigen contractgegevens': 4, 'A_APPROVED': 1}\n",
      " \n",
      "Number of events: 214377\n",
      "Number of cases: 10469\n"
     ]
    }
   ],
   "source": [
    "### IMPORT TRAIN DATA ###\n",
    "\n",
    "file = \"data/added_features_event_log_update_train.csv\"\n",
    "event_log = import_csv(file)\n",
    "event_names_list = list(event_log[event_column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a03eba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start activities: {'A_SUBMITTED': 2618}\n",
      "\n",
      "End activities: {'A_DECLINED': 739, 'W_Completeren aanvraag': 468, 'W_Valideren aanvraag': 454, 'W_Nabellen offertes': 389, 'W_Afhandelen leads': 388, 'W_Nabellen incomplete dossiers': 114, 'A_CANCELLED': 43, 'O_CANCELLED': 15, 'W_Beoordelen fraude': 8}\n",
      " \n",
      "Number of events: 47823\n",
      "Number of cases: 2618\n"
     ]
    }
   ],
   "source": [
    "### IMPORT TEST DATA ###\n",
    "\n",
    "file = \"data/added_features_event_log_update_test.csv\"\n",
    "test_event_log = import_csv(file)\n",
    "test_event_names_list = list(test_event_log[event_column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a0c0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG FEATURE -> number of new cases in that day\n",
    "\n",
    "# first we add a column with the day number(day_of_year)\n",
    "\n",
    "test_event_log[day_of_year_column] = [date.day_of_year for date in test_event_log[timestamp_column]]\n",
    "\n",
    "event_log[day_of_year_column] = [date.day_of_year for date in event_log[timestamp_column]]\n",
    "\n",
    "# now we want to see how many new cases were submitted that day until the given even/row\n",
    "\n",
    "test_event_log[position_column] =  test_event_log.groupby(case_column).cumcount() + 1  # create the position column\n",
    "test_event_log[started_today_column] = test_event_log[test_event_log[position_column]==1].groupby(day_of_year_column).cumcount() + 1  # cummulative sum per day for all events that have the position 1 \n",
    "test_event_log[started_today_column] = test_event_log.groupby(day_of_year_column)[started_today_column].fillna(method='ffill')  # now we fill the NaN values after the first event that started that day\n",
    "test_event_log[started_today_column] = test_event_log[started_today_column].fillna(0)  # finally we fill in all the remaining NaN values with 0; these are the events that happen before the first event where position == 1\n",
    "\n",
    "event_log[position_column] =  event_log.groupby(case_column).cumcount() + 1  # create the position column\n",
    "event_log[started_today_column] = event_log[event_log[position_column]==1].groupby(day_of_year_column).cumcount() + 1  # cummulative sum per day for all events that have the position 1 \n",
    "event_log[started_today_column] = event_log.groupby(day_of_year_column)[started_today_column].fillna(method='ffill')  # now we fill the NaN values after the first event that started that day\n",
    "event_log[started_today_column] = event_log[started_today_column].fillna(0)  # finally we fill in all the remaining NaN values with 0; these are the events that happen before the first event where position == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6968fe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make column with previous day of year since that's what we use for RF\n",
    "\n",
    "test_event_log[prev_started_today_column] = np.nan\n",
    "test_event_log[prev_started_today_column] = test_event_log.groupby(case_column)[started_today_column].shift(1)\n",
    "test_event_log[prev_started_today_column] = test_event_log[prev_started_today_column].fillna(-1) # it's not relevant what we fill it in with because we'll never have to predict the first event of a trace\n",
    "\n",
    "event_log[prev_started_today_column] = np.nan\n",
    "event_log[prev_started_today_column] = event_log.groupby(case_column)[started_today_column].shift(1)\n",
    "event_log[prev_started_today_column] = event_log[prev_started_today_column].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0898b655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous position column\n",
    "test_event_log[previous_position_column] = np.nan\n",
    "test_event_log[previous_position_column] = test_event_log.groupby(case_column)[position_column].shift(1)\n",
    "test_event_log[previous_position_column] = test_event_log[previous_position_column].fillna(-1)\n",
    "\n",
    "event_log[previous_position_column] = np.nan\n",
    "event_log[previous_position_column] = event_log.groupby(case_column)[position_column].shift(1)\n",
    "event_log[previous_position_column] = event_log[previous_position_column].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba04c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOG FEATURE -> most common event name for that position (until the occurence of the current event - we don't count the future events)\n",
    "dict_pos_events = {}\n",
    "def most_common_event(event_name, position):\n",
    "    if (position in dict_pos_events):\n",
    "        if (event_name in dict_pos_events[position]):\n",
    "            dict_pos_events[position][event_name] = dict_pos_events[position][event_name] + 1\n",
    "        else:\n",
    "            dict_pos_events[position][event_name] = 1\n",
    "    else:\n",
    "        dict_pos_events[position] = {}\n",
    "        dict_pos_events[position][event_name] = 1\n",
    "    return max(dict_pos_events[position], key=dict_pos_events[position].get)\n",
    "\n",
    "event_log[most_common_column] = [most_common_event(event_name, position) for event_name, position in zip(event_log[event_column], event_log[position_column])]\n",
    "\n",
    "dict_pos_events = {}\n",
    "def most_common_event(event_name, position):\n",
    "    if (position in dict_pos_events):\n",
    "        if (event_name in dict_pos_events[position]):\n",
    "            dict_pos_events[position][event_name] = dict_pos_events[position][event_name] + 1\n",
    "        else:\n",
    "            dict_pos_events[position][event_name] = 1\n",
    "    else:\n",
    "        dict_pos_events[position] = {}\n",
    "        dict_pos_events[position][event_name] = 1\n",
    "    return max(dict_pos_events[position], key=dict_pos_events[position].get)\n",
    "\n",
    "test_event_log[most_common_column] = [most_common_event(event_name, position) for event_name, position in zip(test_event_log[event_column], test_event_log[position_column])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5e5f48",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_event_log[previous_most_common_column] = np.nan\n",
    "test_event_log[previous_most_common_column] = test_event_log.groupby(case_column)[most_common_column].shift(1)\n",
    "test_event_log[previous_most_common_column] = test_event_log[previous_most_common_column].fillna(-1)\n",
    "\n",
    "event_log[previous_most_common_column] = np.nan\n",
    "event_log[previous_most_common_column] = event_log.groupby(case_column)[most_common_column].shift(1)\n",
    "event_log[previous_most_common_column] = event_log[previous_most_common_column].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dec7fa11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       Unnamed: 0  index        eventID   case concept:name  \\\n0               0      0  44964012621824             206324   \n1               1      1  44964012621825             206324   \n2               2      2  44964012621826             206324   \n3               0      3  44968307589120             206327   \n4               1      4  44968307589121             206327   \n...           ...    ...             ...                ...   \n47818           1  38039  56203942035457             214376   \n47819           2  38040  56203942035458             214376   \n47820           3  38096  56203942035459             214376   \n47821           4  38099  56203942035460             214376   \n47822           5  38100  56203942035461             214376   \n\n                       case REG_DATE  case AMOUNT_REQ  event concept:name  \\\n0      2012-02-03T17:17:11.047+01:00             2500         A_SUBMITTED   \n1      2012-02-03T17:17:11.047+01:00             2500   A_PARTLYSUBMITTED   \n2      2012-02-03T17:17:11.047+01:00             2500          A_DECLINED   \n3      2012-02-03T17:23:41.949+01:00             6000         A_SUBMITTED   \n4      2012-02-03T17:23:41.949+01:00             6000   A_PARTLYSUBMITTED   \n...                              ...              ...                 ...   \n47818  2012-02-29T23:51:16.799+01:00            15000   A_PARTLYSUBMITTED   \n47819  2012-02-29T23:51:16.799+01:00            15000  W_Afhandelen leads   \n47820  2012-02-29T23:51:16.799+01:00            15000  W_Afhandelen leads   \n47821  2012-02-29T23:51:16.799+01:00            15000          A_DECLINED   \n47822  2012-02-29T23:51:16.799+01:00            15000  W_Afhandelen leads   \n\n      event lifecycle:transition    event time:timestamp  @@index  ...  \\\n0                       COMPLETE 2012-02-03 17:17:11.047        0  ...   \n1                       COMPLETE 2012-02-03 17:17:11.323        1  ...   \n2                       COMPLETE 2012-02-03 17:17:42.964        2  ...   \n3                       COMPLETE 2012-02-03 17:23:41.949        3  ...   \n4                       COMPLETE 2012-02-03 17:23:42.504        4  ...   \n...                          ...                     ...      ...  ...   \n47818                   COMPLETE 2012-02-29 23:51:17.423    47818  ...   \n47819                   SCHEDULE 2012-02-29 23:52:01.287    47819  ...   \n47820                      START 2012-03-01 09:26:46.736    47820  ...   \n47821                   COMPLETE 2012-03-01 09:27:37.118    47821  ...   \n47822                   COMPLETE 2012-03-01 09:27:41.325    47822  ...   \n\n      case:concept:name        concept:name          time:timestamp  \\\n0                206324         A_SUBMITTED 2012-02-03 17:17:11.047   \n1                206324   A_PARTLYSUBMITTED 2012-02-03 17:17:11.323   \n2                206324          A_DECLINED 2012-02-03 17:17:42.964   \n3                206327         A_SUBMITTED 2012-02-03 17:23:41.949   \n4                206327   A_PARTLYSUBMITTED 2012-02-03 17:23:42.504   \n...                 ...                 ...                     ...   \n47818            214376   A_PARTLYSUBMITTED 2012-02-29 23:51:17.423   \n47819            214376  W_Afhandelen leads 2012-02-29 23:52:01.287   \n47820            214376  W_Afhandelen leads 2012-03-01 09:26:46.736   \n47821            214376          A_DECLINED 2012-03-01 09:27:37.118   \n47822            214376  W_Afhandelen leads 2012-03-01 09:27:41.325   \n\n       day_of_year  position  started_today  previous_started_today  \\\n0               34         1            1.0                    -1.0   \n1               34         2            1.0                     1.0   \n2               34         3            1.0                     1.0   \n3               34         1            2.0                    -1.0   \n4               34         2            2.0                     2.0   \n...            ...       ...            ...                     ...   \n47818           60         2          138.0                   138.0   \n47819           60         3          138.0                   138.0   \n47820           61         4            0.0                   138.0   \n47821           61         5            0.0                     0.0   \n47822           61         6            0.0                     0.0   \n\n       previous_position  most_common_event_name  \\\n0                   -1.0             A_SUBMITTED   \n1                    1.0       A_PARTLYSUBMITTED   \n2                    2.0              A_DECLINED   \n3                   -1.0             A_SUBMITTED   \n4                    1.0       A_PARTLYSUBMITTED   \n...                  ...                     ...   \n47818                1.0       A_PARTLYSUBMITTED   \n47819                2.0           A_PREACCEPTED   \n47820                3.0  W_Completeren aanvraag   \n47821                4.0  W_Completeren aanvraag   \n47822                5.0  W_Completeren aanvraag   \n\n       previous_most_common_event_name  \n0                                   -1  \n1                          A_SUBMITTED  \n2                    A_PARTLYSUBMITTED  \n3                                   -1  \n4                          A_SUBMITTED  \n...                                ...  \n47818                      A_SUBMITTED  \n47819                A_PARTLYSUBMITTED  \n47820                    A_PREACCEPTED  \n47821           W_Completeren aanvraag  \n47822           W_Completeren aanvraag  \n\n[47823 rows x 47 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>index</th>\n      <th>eventID</th>\n      <th>case concept:name</th>\n      <th>case REG_DATE</th>\n      <th>case AMOUNT_REQ</th>\n      <th>event concept:name</th>\n      <th>event lifecycle:transition</th>\n      <th>event time:timestamp</th>\n      <th>@@index</th>\n      <th>...</th>\n      <th>case:concept:name</th>\n      <th>concept:name</th>\n      <th>time:timestamp</th>\n      <th>day_of_year</th>\n      <th>position</th>\n      <th>started_today</th>\n      <th>previous_started_today</th>\n      <th>previous_position</th>\n      <th>most_common_event_name</th>\n      <th>previous_most_common_event_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>44964012621824</td>\n      <td>206324</td>\n      <td>2012-02-03T17:17:11.047+01:00</td>\n      <td>2500</td>\n      <td>A_SUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>2012-02-03 17:17:11.047</td>\n      <td>0</td>\n      <td>...</td>\n      <td>206324</td>\n      <td>A_SUBMITTED</td>\n      <td>2012-02-03 17:17:11.047</td>\n      <td>34</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>A_SUBMITTED</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>44964012621825</td>\n      <td>206324</td>\n      <td>2012-02-03T17:17:11.047+01:00</td>\n      <td>2500</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>2012-02-03 17:17:11.323</td>\n      <td>1</td>\n      <td>...</td>\n      <td>206324</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>2012-02-03 17:17:11.323</td>\n      <td>34</td>\n      <td>2</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>A_SUBMITTED</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>44964012621826</td>\n      <td>206324</td>\n      <td>2012-02-03T17:17:11.047+01:00</td>\n      <td>2500</td>\n      <td>A_DECLINED</td>\n      <td>COMPLETE</td>\n      <td>2012-02-03 17:17:42.964</td>\n      <td>2</td>\n      <td>...</td>\n      <td>206324</td>\n      <td>A_DECLINED</td>\n      <td>2012-02-03 17:17:42.964</td>\n      <td>34</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>A_DECLINED</td>\n      <td>A_PARTLYSUBMITTED</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>44968307589120</td>\n      <td>206327</td>\n      <td>2012-02-03T17:23:41.949+01:00</td>\n      <td>6000</td>\n      <td>A_SUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>2012-02-03 17:23:41.949</td>\n      <td>3</td>\n      <td>...</td>\n      <td>206327</td>\n      <td>A_SUBMITTED</td>\n      <td>2012-02-03 17:23:41.949</td>\n      <td>34</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>A_SUBMITTED</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>4</td>\n      <td>44968307589121</td>\n      <td>206327</td>\n      <td>2012-02-03T17:23:41.949+01:00</td>\n      <td>6000</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>2012-02-03 17:23:42.504</td>\n      <td>4</td>\n      <td>...</td>\n      <td>206327</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>2012-02-03 17:23:42.504</td>\n      <td>34</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>A_SUBMITTED</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>47818</th>\n      <td>1</td>\n      <td>38039</td>\n      <td>56203942035457</td>\n      <td>214376</td>\n      <td>2012-02-29T23:51:16.799+01:00</td>\n      <td>15000</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>COMPLETE</td>\n      <td>2012-02-29 23:51:17.423</td>\n      <td>47818</td>\n      <td>...</td>\n      <td>214376</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>2012-02-29 23:51:17.423</td>\n      <td>60</td>\n      <td>2</td>\n      <td>138.0</td>\n      <td>138.0</td>\n      <td>1.0</td>\n      <td>A_PARTLYSUBMITTED</td>\n      <td>A_SUBMITTED</td>\n    </tr>\n    <tr>\n      <th>47819</th>\n      <td>2</td>\n      <td>38040</td>\n      <td>56203942035458</td>\n      <td>214376</td>\n      <td>2012-02-29T23:51:16.799+01:00</td>\n      <td>15000</td>\n      <td>W_Afhandelen leads</td>\n      <td>SCHEDULE</td>\n      <td>2012-02-29 23:52:01.287</td>\n      <td>47819</td>\n      <td>...</td>\n      <td>214376</td>\n      <td>W_Afhandelen leads</td>\n      <td>2012-02-29 23:52:01.287</td>\n      <td>60</td>\n      <td>3</td>\n      <td>138.0</td>\n      <td>138.0</td>\n      <td>2.0</td>\n      <td>A_PREACCEPTED</td>\n      <td>A_PARTLYSUBMITTED</td>\n    </tr>\n    <tr>\n      <th>47820</th>\n      <td>3</td>\n      <td>38096</td>\n      <td>56203942035459</td>\n      <td>214376</td>\n      <td>2012-02-29T23:51:16.799+01:00</td>\n      <td>15000</td>\n      <td>W_Afhandelen leads</td>\n      <td>START</td>\n      <td>2012-03-01 09:26:46.736</td>\n      <td>47820</td>\n      <td>...</td>\n      <td>214376</td>\n      <td>W_Afhandelen leads</td>\n      <td>2012-03-01 09:26:46.736</td>\n      <td>61</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>138.0</td>\n      <td>3.0</td>\n      <td>W_Completeren aanvraag</td>\n      <td>A_PREACCEPTED</td>\n    </tr>\n    <tr>\n      <th>47821</th>\n      <td>4</td>\n      <td>38099</td>\n      <td>56203942035460</td>\n      <td>214376</td>\n      <td>2012-02-29T23:51:16.799+01:00</td>\n      <td>15000</td>\n      <td>A_DECLINED</td>\n      <td>COMPLETE</td>\n      <td>2012-03-01 09:27:37.118</td>\n      <td>47821</td>\n      <td>...</td>\n      <td>214376</td>\n      <td>A_DECLINED</td>\n      <td>2012-03-01 09:27:37.118</td>\n      <td>61</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>W_Completeren aanvraag</td>\n      <td>W_Completeren aanvraag</td>\n    </tr>\n    <tr>\n      <th>47822</th>\n      <td>5</td>\n      <td>38100</td>\n      <td>56203942035461</td>\n      <td>214376</td>\n      <td>2012-02-29T23:51:16.799+01:00</td>\n      <td>15000</td>\n      <td>W_Afhandelen leads</td>\n      <td>COMPLETE</td>\n      <td>2012-03-01 09:27:41.325</td>\n      <td>47822</td>\n      <td>...</td>\n      <td>214376</td>\n      <td>W_Afhandelen leads</td>\n      <td>2012-03-01 09:27:41.325</td>\n      <td>61</td>\n      <td>6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>W_Completeren aanvraag</td>\n      <td>W_Completeren aanvraag</td>\n    </tr>\n  </tbody>\n</table>\n<p>47823 rows × 47 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_event_log[test_event_log[case_column]==206366][:]  # see this for an example\n",
    "test_event_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15ccaaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURESPACES ###\n",
    "if not added_features:\n",
    "    test_event_log[previous_event_column] = test_event_log.groupby(case_column)[event_column].shift(1)\n",
    "    event_log[previous_event_column] = event_log.groupby(case_column)[event_column].shift(1)\n",
    "\n",
    "    test_event_log[previous_lifecycle_column] = test_event_log.groupby(case_column)[lifecycle_column].shift(1)\n",
    "    event_log[previous_lifecycle_column] = event_log.groupby(case_column)[lifecycle_column].shift(1)\n",
    "\n",
    "\n",
    "\n",
    "# FeatureSpace 1\n",
    "X_1 = event_log[[previous_position_column, prev_started_today_column, previous_event_column, previous_lifecycle_column]]\n",
    "\n",
    "X_1 = pd.get_dummies(X_1)\n",
    "\n",
    "# Labels\n",
    "y = event_log[event_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65c0eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURESPACES - test ###\n",
    "\n",
    "# FeatureSpace 1\n",
    "X_1_test = test_event_log[[previous_position_column, prev_started_today_column, previous_event_column, previous_lifecycle_column]]\n",
    "\n",
    "X_1_test = pd.get_dummies(X_1_test)\n",
    "\n",
    "# Labels\n",
    "y_test = test_event_log[event_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5644018",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Make sure the two sets have the same columns, otherwise we get errors when trying to run the RF model\n",
    "\n",
    "for column in list(set(X_1_test).difference(X_1)):\n",
    "    X_1[column] = 0\n",
    "\n",
    "for column in list(set(X_1).difference(X_1_test)):\n",
    "    X_1_test[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e16f2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "if added_features:\n",
    "    if data_2012:\n",
    "        # FeatureSpace 2\n",
    "        X_2 = event_log[[prev_started_today_column, previous_position_column, req_amount_column, previous_most_common_column, previous_event_column, previous_lifecycle_column] + test_event_names_list + list(set(event_names_list).difference(test_event_names_list))]\n",
    "        X_2 = pd.get_dummies(X_2)\n",
    "\n",
    "        X_2_test = test_event_log[[prev_started_today_column, previous_position_column, req_amount_column, previous_most_common_column, previous_event_column, previous_lifecycle_column] + test_event_names_list]\n",
    "        X_2_test = pd.get_dummies(X_2_test)\n",
    "\n",
    "        for column in list(set(X_2_test).difference(X_2)):\n",
    "            X_2[column] = 0\n",
    "\n",
    "        for column in list(set(X_2).difference(X_2_test)):\n",
    "            X_2_test[column] = 0\n",
    "\n",
    "    else:\n",
    "        # FeatureSpace 2\n",
    "        X_2 = event_log[[prev_started_today_column, previous_position_column, previous_most_common_column, previous_event_column, previous_lifecycle_column] + test_event_names_list + list(set(event_names_list).difference(test_event_names_list))]\n",
    "        X_2 = pd.get_dummies(X_2)\n",
    "\n",
    "        X_2_test = test_event_log[[prev_started_today_column, previous_position_column, previous_most_common_column, previous_event_column, previous_lifecycle_column] + test_event_names_list]\n",
    "        X_2_test = pd.get_dummies(X_2_test)\n",
    "\n",
    "        for column in list(set(X_2_test).difference(X_2)):\n",
    "            X_2[column] = 0\n",
    "\n",
    "        for column in list(set(X_2).difference(X_2_test)):\n",
    "            X_2_test[column] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1010e8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average 5 fold cross validation accuracy for RandomForest on FeatureSpace 1 is:  0.7646622372686631\n",
      "The test accuracy for RandomForest on FeatureSpace 1 is:  0.5483344834075654\n",
      "The average 5 fold cross validation accuracy for RandomForest on FeatureSpace 2 is:  0.8368015079079492\n",
      "The test accuracy for RandomForest on FeatureSpace 2 is:  0.7370093887878217\n"
     ]
    }
   ],
   "source": [
    "### RandomForest ###\n",
    "\n",
    "# FeatureSpace 1\n",
    "rf_1 = RandomForestClassifier(max_depth=15, random_state=0)\n",
    "X_1_cv_rf = np.mean(cross_val_score(rf_1, X_1, y, cv=5))\n",
    "print('The average 5 fold cross validation accuracy for RandomForest on FeatureSpace 1 is: ', X_1_cv_rf)\n",
    "rf_1.fit(X_1, y)\n",
    "print('The test accuracy for RandomForest on FeatureSpace 1 is: ', rf_1.score(X_1_test, y_test))\n",
    "\n",
    "if added_features:\n",
    "    # FeatureSpace 2\n",
    "    rf_2 = RandomForestClassifier(max_depth=15, random_state=0)\n",
    "    X_2_cv_rf = np.mean(cross_val_score(rf_2, X_2, y, cv=5))\n",
    "    print('The average 5 fold cross validation accuracy for RandomForest on FeatureSpace 2 is: ', X_2_cv_rf)\n",
    "    rf_2.fit(X_2, y)\n",
    "    print('The test accuracy for RandomForest on FeatureSpace 2 is: ', rf_2.score(X_2_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4457de22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### RANDOM FOREST ### => this is optimization, so you don't have to run this anymore\n",
    "\n",
    "\n",
    "# # Since the data is flattened, we can use cross validation.\n",
    "# # To optimize a random forest, one can play around with the depth of the trees.\n",
    "# depths = [1,2,3,4,5,6,7,8,9,10,15,20]\n",
    "# X_1_rf_scores = pd.DataFrame()\n",
    "# X_2_rf_scores = pd.DataFrame()\n",
    "# for depth in depths:\n",
    "#     clf = RandomForestClassifier(max_depth=depth, random_state=0)\n",
    "#     X_1_rf_scores[depth] = cross_val_score(clf, X_1, y, cv=5)\n",
    "#     X_2_rf_scores[depth] = cross_val_score(clf, X_2, y, cv=5)\n",
    "\n",
    "\n",
    "\n",
    "# # plot all the traces for featureSpace 1\n",
    "# fig = go.Figure()\n",
    "\n",
    "# for depth in depths:\n",
    "#     fig.add_trace(go.Scatter(y= X_1_rf_scores[depth], name=depth))\n",
    "# fig.update_yaxes(range=[0,1], title='Accuracy')\n",
    "# fig.update_xaxes(title='5 fold cross validation')\n",
    "# fig.update_layout(title= '5 fold cross validation on random forest on featureSpace X_1, for different tree depths.',\n",
    "#                   legend_title_text='tree depths')\n",
    "# fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# # plot all the traces for featureSpace 2\n",
    "# fig = go.Figure()\n",
    "\n",
    "# for depth in depths:\n",
    "#     fig.add_trace(go.Scatter(y= X_2_rf_scores[depth], name=depth))\n",
    "# fig.update_yaxes(range=[0,1], title='Accuracy')\n",
    "# fig.update_xaxes(title='5 fold cross validation')\n",
    "# fig.update_layout(title= '5 fold cross validation on random forest on featureSpace X_2, for different tree depths.',\n",
    "#                   legend_title_text='tree depths')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d20c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### OPTIMIZED MODELS ### => this is optimization, so you don't have to run this anymore\n",
    "\n",
    "# optimal_depth_X_1 = 15\n",
    "# optimal_depth_X_2 = 15\n",
    "\n",
    "# # optimal_k_X_1 = 50\n",
    "# # optimal_k_X_2 = 50\n",
    "\n",
    "# # average accuracy\n",
    "# X_1_rf = np.mean(X_1_rf_scores[optimal_depth_X_1])\n",
    "# X_2_rf = np.mean(X_2_rf_scores[optimal_depth_X_2])\n",
    "# # X_1_knn = np.mean(X_1_knn_scores[optimal_k_X_1])\n",
    "# # X_2_knn = np.mean(X_2_knn_scores[optimal_k_X_2])\n",
    "# baseline = round(((my_counter.most_common(1)[0][1])/len(event_log)), 2)\n",
    "\n",
    "# # make a plot with all values\n",
    "# fig = go.Figure()\n",
    "\n",
    "# fig.add_trace(go.Scatter(x=['X_1', 'X_2'], y= [baseline, baseline], name='Baseline'))\n",
    "# fig.add_trace(go.Scatter(x=['X_1', 'X_2'], y= [X_1_rf, X_2_rf], name='RandomForest'))\n",
    "# # fig.add_trace(go.Scatter(x=['X_1', 'X_2'], y= [X_1_knn, X_2_knn], name='KNN'))\n",
    "\n",
    "# fig.update_yaxes(range=[0,1], title='Accuracy')\n",
    "# fig.update_xaxes(title='mean 5 fold cross validation per featureSpace')\n",
    "# fig.update_layout(title= '5 fold cross validation on randomForest and knn on featureSpaces X_1 and X_2.',\n",
    "#                   legend_title_text='algorithm')\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99f2632a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Results with previous_started_today and previous_position:\n",
    "# F1: CV: 0.7670 and test: 0.5085\n",
    "# F2: CV: 0.8394 and test: 0.6932\n",
    "\n",
    "# Results with previous_started_today and previous_position, but WITHOUT requested amount:\n",
    "# F1: CV: 0.7656 and test: 0.4977\n",
    "# F2: CV: 0.8369 and test: 0.6930\n",
    "\n",
    "# Results with previous_position:\n",
    "# F1: CV: 0.7624 and test: 0.4173\n",
    "# F2: CV: 0.8398 and test: 0.7092\n",
    "\n",
    "# Results with previous_started_today:\n",
    "# F1: CV: 0.7223 and test: 0.4190\n",
    "# F2: CV: 0.8378 and test: 0.6655"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}